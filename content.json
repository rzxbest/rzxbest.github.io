{"meta":{"title":"随记","subtitle":"记一记,所学,温故而知新","description":"","author":"Ren zheng xiao","url":"https://blog.imder.top","root":"/"},"pages":[{"title":"归档","date":"2021-11-26T18:27:29.000Z","updated":"2024-03-28T16:43:20.083Z","comments":true,"path":"categories/index.html","permalink":"https://blog.imder.top/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-02-22T10:27:29.000Z","updated":"2024-03-28T16:43:20.083Z","comments":true,"path":"tags/index.html","permalink":"https://blog.imder.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"zookeeper","slug":"zookeeper","date":"2022-04-22T12:43:00.000Z","updated":"2024-03-28T16:43:20.075Z","comments":true,"path":"2022/04/22/zookeeper/","link":"","permalink":"https://blog.imder.top/2022/04/22/zookeeper/","excerpt":"","text":"zookeeper选举服务器节点状态 ： LOOKING 竞选状态,FOLLOWING 随从状态,LEADING 领导状态,OBSERVING 观察状态，不参与投票服务器ID ：sid事务ID ：zxid 规则：交换投票信息，对方事务id比自己大的，下一次投票投给对方节点，如果事务id相同，服务器id比自己大的，下一次投票给对方节点，多个取最大，投票给最大；当选票大于总节点一半时，选票多的机器变为leader,其余变成follow 假设5台机器1.服务器1启动，投票给自己，（zxid=0,sid=1）,只有一票2.服务器2启动，投票给自己，（zxid=0,sid=2）,并和服务器1交换信息，服务器1更改选票投给服务器2 ，服务器2只有两票3.服务器3启动，投票给自己，（zxid=0,sid=3）,并和服务器1、2交换信息，服务器1、2更改选票投给服务器3 ，服务器3只有三票 》2.5 ，成为leader ，服务器1，2成功follow4. 服务器4启动，投票给自己 ，（zxid=0,sid=4）, 并和服务器1，2，3交换选票，但是此时服务器1，2，3已经不是looking状态，服务器3 3票，服务器 4 1票，服务器4成为follow5. 服务器5启动，投票给自己 ，（zxid=0,sid=3）, 并和服务器1，2，3，4交换选票，但是此时服务器1，2，3，4已经不是looking状态，服务器3 4票，服务器5 1票，服务器5成为follow leader挂了选举新leader？服务器投票给自己，服务器1 （zxid=99,sid=1）服务器2 （zxid=102,sid=2）服务器4 （zxid=99,sid=4）服务器5 （zxid=99,sid=5），并交换选票信息，接下来改投票给服务器2，服务器2成为leader","categories":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.imder.top/categories/zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.imder.top/tags/zookeeper/"}]},{"title":"多线程","slug":"多线程","date":"2022-04-22T11:43:00.000Z","updated":"2024-03-28T16:43:20.075Z","comments":true,"path":"2022/04/22/多线程/","link":"","permalink":"https://blog.imder.top/2022/04/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"多线程线程数量与cpu的关系如果是CPU密集型应用，则线程池大小设置为N+1如果是IO密集型应用，则线程池大小设置为2N+1（因为io读数据或者缓存的时候，线程等待，此时如果多开线程，能有效提高cpu利用率） 最佳线程数目 = （（线程等待时间（非CPU运行时间，比如IO）+线程CPU时间）/线程CPU时间 ）* CPU数目线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目","categories":[{"name":"多线程","slug":"多线程","permalink":"https://blog.imder.top/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://blog.imder.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"springboot-tomcat启动","slug":"springboot-tomcat启动","date":"2022-04-12T14:59:29.000Z","updated":"2024-03-28T16:43:20.067Z","comments":true,"path":"2022/04/12/springboot-tomcat启动/","link":"","permalink":"https://blog.imder.top/2022/04/12/springboot-tomcat%E5%90%AF%E5%8A%A8/","excerpt":"","text":"","categories":[{"name":"springboot","slug":"springboot","permalink":"https://blog.imder.top/categories/springboot/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://blog.imder.top/tags/tomcat/"},{"name":"springboot","slug":"springboot","permalink":"https://blog.imder.top/tags/springboot/"}]},{"title":"消金内部服务调用框架sif","slug":"消金内部服务调用框架sif","date":"2022-04-12T14:59:29.000Z","updated":"2024-03-28T16:43:20.083Z","comments":true,"path":"2022/04/12/消金内部服务调用框架sif/","link":"","permalink":"https://blog.imder.top/2022/04/12/%E6%B6%88%E9%87%91%E5%86%85%E9%83%A8%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E6%A1%86%E6%9E%B6sif/","excerpt":"","text":"服务端流程 客户端流程","categories":[{"name":"微服务","slug":"微服务","permalink":"https://blog.imder.top/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://blog.imder.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"远程服务调用","slug":"远程服务调用","permalink":"https://blog.imder.top/tags/%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8/"}]},{"title":"Spring","slug":"spring","date":"2022-03-31T14:59:29.000Z","updated":"2024-03-28T16:43:20.067Z","comments":true,"path":"2022/03/31/spring/","link":"","permalink":"https://blog.imder.top/2022/03/31/spring/","excerpt":"","text":"Spring注册组件方法 1.包扫描+组件标注注解（@Controller/@Service/@Repository/@Component）[自己写的类] 2.@Bean[导入的第三方包里面的组件] 3.@Import[快速给容器中导入一个组件] 1.@Import(要导入到容器中的组件)；容器中就会自动注册这个组件，id默认是全类名 2.ImportSelector接口:返回需要导入的组件的全类名数组； 3.ImportBeanDefinitionRegistrar接口:手动注册bean到容器中 spring 扩展点spring启动流程图 BeanFactoryPostProcessor允许对Bean的定义进行修改，向ConfigurableListableBeanFactory里注册spring 的组件，比如添加 BeanPostProcessor、ApplicationListener、类型转换器等等 123public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 应用 单元测试懒加载 有时候整个项目工程中bean的数量有上百个，而大部分单测依赖都是整个工程的xml，导致单测执行时需要很长时间（大部分时间耗费在xml中数百个单例非懒加载的bean的实例化及初始化过程） 解决方法：利用Spring提供的扩展点将xml中的bean设置为懒加载模式，省去了Bean的实例化与初始化时间 BeanFactoryPostProcessor 来处理占位符 ${…}，关键的实现类是 PropertySourcesPlaceholderConfigurer，遍历所有的 BeanDefinition，如果 PropertyValue 存在这样的占位符，则会进行解析替换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class LazyBeanFactoryProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; DefaultListableBeanFactory fac = (DefaultListableBeanFactory) beanFactory; Map&lt;String, AbstractBeanDefinition&gt; map = (Map&lt;String, AbstractBeanDefinition&gt;) ReflectionTestUtils.getField(fac, &quot;beanDefinitionMap&quot;); for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : map.entrySet()) &#123; //设置为懒加载 entry.getValue().setLazyInit(true); &#125; &#125;&#125;public class PropertySourcesPlaceholderConfigurer extends PlaceholderConfigurerSupport implements EnvironmentAware &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; // 省略对 PropertySources 的处理逻辑...... processProperties(beanFactory, new PropertySourcesPropertyResolver(this.propertySources)); this.appliedPropertySources = this.propertySources; &#125; protected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, final ConfigurablePropertyResolver propertyResolver) throws BeansException &#123; propertyResolver.setPlaceholderPrefix(this.placeholderPrefix); propertyResolver.setPlaceholderSuffix(this.placeholderSuffix); propertyResolver.setValueSeparator(this.valueSeparator); StringValueResolver valueResolver = new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; String resolved = (ignoreUnresolvablePlaceholders ? propertyResolver.resolvePlaceholders(strVal) : propertyResolver.resolveRequiredPlaceholders(strVal)); if (trimValues) &#123; resolved = resolved.trim(); &#125; return (resolved.equals(nullValue) ? null : resolved); &#125; &#125;; // 调用父类 PlaceholderConfigurerSupport 进行 properties 处理 // 遍历每一个 BeanDefinition，并将其交给 BeanDefinitionVisitor 修改内部的属性 doProcessProperties(beanFactoryToProcess, valueResolver); &#125;&#125; BeanDefinitionRegistryPostProcessorBeanDefinitionRegistryPostProcessor 是 BeanFactoryPostProcessor 的子类，可以通过编码的方式，改变、新增类的定义，甚至删除某些 bean 的定义 123public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException;&#125; 在 spring 初始化容器之后，解析Class 为一个BeanDefinition 之前的时候去执行， spring 中有一个开天辟地的类 ConfigurationClassPostProcessor 就是实现了该接口， ConfigurationClassPostProcessor 通过重写 这个方法 第一步：去扫描加了 @Configuration 注解的这些类，判断是否是AnnotatedBeanDefinition类型的，将这些类去打上 Lite/Full 的属性，以便后续使用 。第二步：去实现扫描basePackage下的加了 @Service @Controller @Component 的这些类 将这些类变成为一个BeanDefinition 注册到 Spring 的BeanDefinitionMap中去 。第三步： 去解析 @import，实现 ImportSelector接口的，实现 ImportBeanDefinitionRegistrar 接口的 这些类的方法，将对应的bean 解析为BeanDefinition，注册到BeanDefinitionMap 中注意： 在新的Mybatis-spring 的框架中，也使用了到了这个接口 MapperScannerConfigurer 这个扫描配置类 也实现了这个接口！ 重写了postProcessBeanDefinitionRegistry() 用于创建扫描器对象，去扫描mybatis 里的那些接口转化为BeanDefinition到容器中去作用： 有了参数 registry 的对象，就能手动向spring容器添加 自定义的BeanDefinition registry 提供了添加的 API，但是一般我们不调用 因为在spring里的执行顺序太早了 应用： spring 集成 mybatis，使用 spring 提供的扫描功能，为我们的Dao接口生成实现类而不需要编写具体的实现类，简化了大量的冗余代码 mybatis-spring 框架就是利用 BeanDefinitionRegistryPostProcessor通过编码的方式往spring容器中添加 bean。 MapperScannerConfigurer 重写了 postProcessBeanDefinitionRegistry方法，扫描Dao接口的BeanDefinition，并将BeanDefinition注册到 spring容器中。 123456789101112131415161718public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; if (this.processPropertyPlaceHolders) &#123; processPropertyPlaceHolders(); &#125; // ClassPathMapperScanner 持有 BeanDefinitionRegistry 引用，可以添加 BeanDefinition ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // 省略部分代码……，设置 ClassPathMapperScanner 各种属性 // 扫描并注册 Dao 接口的 BeanDefinition，当然是通过动态代理实现 scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS)); &#125;&#125; InstantiationAwareBeanPostProcessor接口12345678public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException; boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException; PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException;&#125; BeanPostProcessor的子接口，用于在实例化之后，但在设置显式属性或自动装配之前，设置实例化之前的回调函数。通常用于抑制特定目标bean的默认实例化，例如，创建具有特殊TargetSources（池化目标，延迟初始化目标等）的代理，或者实现其他注入策略，例如字段注入。注意：这个接口是一个专用接口，主要用于框架内的内部使用。 建议尽可能实现简单的BeanPostProcessor接口，或者从InstantiationAwareBeanPostProcessorAdapter派生，以便屏蔽此接口的扩展。 postProcessBeforeInstantiation方法，在目标bean实例化之前创建bean，如果在这里创建了bean，则不会走默认的实例化过程，通常用来创建代理。注意工厂方法生成的bean不会走这个方法。 postProcessAfterInstantiation方法，在目标bean实例化后，但是没有进行属性填充前执行的方法。 postProcessPropertyValues方法，在将给定属性值设置到到给定的bean后，对其进行后处理。 允许检查所有的依赖关系是否被满足，例如基于bean属性设置器上的“Required”注解。还允许替换要应用的属性值，通常通过创建基于原始PropertyValues的新MutablePropertyValues实例，添加或删除特定值。 接口应用 spring不建议用户直接实现，如果必须在这些扩展点应用自己的回调函数，spring建议继承InstantiationAwareBeanPostProcessorAdapter，重写相应的方法即可。 org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator，基于beanName创建代理，就是应用了这个接口，在生成bean前生成代理bean，从而替代默认的实例化。 SmartInstantiationAwareBeanPostProcessor123456789101112public interface SmartInstantiationAwareBeanPostProcessor extends InstantiationAwareBeanPostProcessor &#123; // 预测Bean的类型，返回第一个预测成功的Class类型，如果不能预测返回null Class&lt;?&gt; predictBeanType(Class&lt;?&gt; beanClass, String beanName) throws BeansException;// 选择合适的构造器，比如目标对象有多个构造器，在这里可以进行一些定制化，选择合适的构造器// beanClass参数表示目标实例的类型，beanName是目标实例在Spring容器中的name// 返回值是个构造器数组，如果返回null，会执行下一个PostProcessor的determineCandidateConstructors方法；否则选取该PostProcessor选择的构造器 Constructor&lt;?&gt;[] determineCandidateConstructors(Class&lt;?&gt; beanClass, String beanName) throws BeansException;// 获得提前暴露的bean引用。主要用于解决循环引用的问题// 只有单例对象才会调用此方法 Object getEarlyBeanReference(Object bean, String beanName) throws BeansException;&#125; getEarlyBeanReference调用时机 123456789101112131415protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (bean != null &amp;&amp; !mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); if (exposedObject == null) &#123; return null; &#125; &#125; &#125; &#125; return exposedObject; &#125; determineCandidateConstructors调用时机 检测Bean的构造器，可以检测出多个候选构造器，再有相应的策略决定使用哪一个，如AutowiredAnnotationBeanPostProcessor实现将自动扫描通过@Autowired/@Value注解的构造器从而可以完成构造器注入 BeanPostProcessorBeanPostProcessor允许对bean的实例进行个些自定义的个性，比如检查标记接口、使用代理包装bean实例。spring可以自动检测容器中定义的 BeanPostProcessor，后续创建的bean便会被该BeanPostProcessor处理。 123456789public interface BeanPostProcessor &#123; // 初始化之后被调用，已完成注入，但是尚未执行 InitializingBean#afterPropertiesSet() 方法，或者自定义的 init 方法 Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; // 初始化之后被调用 Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 应用： 注解注入、AOP AnnotationAwareAspectJAutoProxyCreator 在bean的实例化、或者初始化之后创建代理，从而实现 aop 功能。 spring 根据 BeanDefinition 对bean进行实例化之后，会遍历容器内部注册的 InstantiationAwareBeanPostProcessor(BeanPostProcessor的子类)进行属性填充。 AutowiredAnnotationBeanPostProcessor，它会处理 @Autowired、@Value 注解，从而完成注入的功能 CommonAnnotationBeanPostProcessor 也是如此，只是处理不同的注解而已 注解注入的检查机制RequiredAnnotationBeanPostProcessor，执行的优先级较低(通过 Ordered 控制) ApplicationContextAwareProcessor 1234567891011121314151617181920212223class AspectJAutoProxyBeanDefinitionParser implements BeanDefinitionParser &#123; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; //注册特殊的bean AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element); extendBeanDefinition(element, parserContext); return null; &#125;&#125;public class AnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator &#123; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.containsKey(cacheKey)) &#123; //如果该类需要被代理，返回动态代理对象；反之，返回原对象 return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException &#123; // 省略 AccessControlContext 处理的代码 invokeAwareInterfaces(bean); return bean; &#125; private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; // 省略部分代码…… &#125; &#125;&#125;以@Resource为例，看看这个特殊的bean做了什么public class CommonAnnotationBeanPostProcessor extends InitDestroyAnnotationBeanPostProcessor implements InstantiationAwareBeanPostProcessor, BeanFactoryAware, Serializable &#123; public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; InjectionMetadata metadata = findResourceMetadata(beanName, bean.getClass()); try &#123; //属性注入 metadata.inject(bean, beanName, pvs); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, &quot;Injection of resource dependencies failed&quot;, ex); &#125; return pvs; &#125; &#125; invokeAware实现BeanFactoryAware接口的类，会由容器执行setBeanFactory方法将当前的容器BeanFactory注入到类中 123456789@Beanclass BeanFactoryHolder implements BeanFactoryAware&#123; private static BeanFactory beanFactory; public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125;&#125; afterPropertySet()和init-method目前很多Java中间件都是基本Spring Framework搭建的，而这些中间件经常把入口放到afterPropertySet或者自定义的init中 destroy()和destroy-methodbean生命周期的最后一个扩展点，该方法用于执行一些bean销毁前的准备工作，比如将当前bean持有的一些资源释放掉 ApplicationListener用于接收spring的事件通知，比如常用的ContextRefreshedEvent事件，spring 在成功完成refresh动作之后便会发出该事件，代表spring容器已经完成初始化了，可以做一些额外的处理了，比如开启 spring 定时任务、拉取 MQ 消息，等等。spring 处理 @Scheduled 注解的部分实现，在收到 Refresh 事件之后对 ScheduledTaskRegistrar 进行额外的设置，并开启定时任务 12345678910111213public class ScheduledAnnotationBeanPostProcessor implements MergedBeanDefinitionPostProcessor, DestructionAwareBeanPostProcessor, Ordered, EmbeddedValueResolverAware, BeanNameAware, BeanFactoryAware, ApplicationContextAware, SmartInitializingSingleton, ApplicationListener&lt;ContextRefreshedEvent&gt;, DisposableBean &#123; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; if (event.getApplicationContext() == this.applicationContext) &#123; finishRegistration(); // 对 ScheduledTaskRegistrar 进行额外的设置，并开启定时任务 &#125; &#125; // 其它代码......&#125; FactoryBean 扩展点FactoryBean主要用来定制化Bean的创建逻辑。 FactoryBean 接口提供了三个方法： Object getObject()：返回这个 FactoryBean 所创建的对象。 boolean isSingleton()：返回 FactoryBean 所创建的对象是否为单例，默认返回 true。 Class getObjectType()：返回这个 FactoryBean 所创建的对象的类型，如果我们能确认返回对象的类型的话，我们应该正常对这个方法做出实现，而不是返回 null。 假设定义了一个FactoryBean，名为MyFactoryBean，当我们调用 getBean(“MyFactoryBean”)方法时返回的并不是这个FactoryBean，而是这个FactoryBean所创建的 Bean，如果我们想获取到这个FactoryBean 需要在名字前面拼接”&amp;”，例如这种形式：getBean(“&amp;MyFactoryBean”) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public static boolean isFactoryDereference(@Nullable String name) &#123; return name != null &amp;&amp; name.startsWith(&quot;&amp;&quot;);&#125;protected Object getObjectForBeanInstance(Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &#123; //判断beanName是不是&amp;开头 if (BeanFactoryUtils.isFactoryDereference(name)) &#123; if (beanInstance instanceof NullBean) &#123; return beanInstance; &#125; else if (!(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(beanName, beanInstance.getClass()); &#125; else &#123; if (mbd != null) &#123; mbd.isFactoryBean = true; &#125; return beanInstance; &#125; &#125;//判断beanInstance 不是factory bean的子类直接返回 else if (!(beanInstance instanceof FactoryBean)) &#123; return beanInstance; &#125; // beanname非&amp;开头，且factory bean的子类 else &#123; Object object = null; if (mbd != null) &#123; mbd.isFactoryBean = true; &#125; else &#123; //从缓存里取对象 object = this.getCachedObjectForFactoryBean(beanName); &#125; //缓存没有取到 if (object == null) &#123; FactoryBean&lt;?&gt; factory = (FactoryBean)beanInstance; if (mbd == null &amp;&amp; this.containsBeanDefinition(beanName)) &#123; mbd = this.getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = mbd != null &amp;&amp; mbd.isSynthetic(); //调用factorybean getobject方法 object = this.getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object; &#125;&#125;protected Object getObjectFromFactoryBean(FactoryBean&lt;?&gt; factory, String beanName, boolean shouldPostProcess) &#123; if (factory.isSingleton() &amp;&amp; this.containsSingleton(beanName)) &#123; synchronized(this.getSingletonMutex()) &#123; Object object = this.factoryBeanObjectCache.get(beanName); if (object == null) &#123; //调用factorybean getobject方法 object = this.doGetObjectFromFactoryBean(factory, beanName); Object alreadyThere = this.factoryBeanObjectCache.get(beanName); if (alreadyThere != null) &#123; object = alreadyThere; &#125; else &#123; if (shouldPostProcess) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; return object; &#125; this.beforeSingletonCreation(beanName); try &#123; object = this.postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable var14) &#123; throw new BeanCreationException(beanName, &quot;Post-processing of FactoryBean&#x27;s singleton object failed&quot;, var14); &#125; finally &#123; this.afterSingletonCreation(beanName); &#125; &#125; //判断是否单例，存缓存里 if (this.containsSingleton(beanName)) &#123; this.factoryBeanObjectCache.put(beanName, object); &#125; &#125; &#125; &#125; &#125;&#125; 扩展点之间的调用顺序","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/categories/Spring/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/tags/Spring/"}]},{"title":"redis","slug":"redis","date":"2022-03-31T09:10:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2022/03/31/redis/","link":"","permalink":"https://blog.imder.top/2022/03/31/redis/","excerpt":"","text":"redisaof重写aof重写原因 AOF 持久化是通过保存被执行的写命令来记录数据库状态的，所以AOF文件的大小随着时间的流逝一定会越来越大；影响包括但不限于：对于Redis服务器，计算机的存储压力；AOF还原出数据库状态的时间增加； 为了解决AOF文件体积膨胀的问题，Redis提供了AOF重写功能：Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个文件所保存的数据库状态是相同的，但是新的AOF文件不会包含任何浪费空间的冗余命令，通常体积会较旧AOF文件小很多。 AOF重写功能的实现原理AOF重写功能的实现原理：从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录该键值对的多个命令; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475def AOF_REWRITE(tmp_tile_name): f = create(tmp_tile_name) # 遍历所有数据库 for db in redisServer.db: # 如果数据库为空，那么跳过这个数据库 if db.is_empty(): continue # 写入 SELECT 命令，用于切换数据库 f.write_command(&quot;SELECT &quot; + db.number) # 遍历所有键 for key in db: # 如果键带有过期时间，并且已经过期，那么跳过这个键 if key.have_expire_time() and key.is_expired(): continue if key.type == String: # 用 SET key value 命令来保存字符串键 value = get_value_from_string(key) f.write_command(&quot;SET &quot; + key + value) elif key.type == List: # 用 RPUSH key item1 item2 ... itemN 命令来保存列表键 item1, item2, ..., itemN = get_item_from_list(key) f.write_command(&quot;RPUSH &quot; + key + item1 + item2 + ... + itemN) elif key.type == Set: # 用 SADD key member1 member2 ... memberN 命令来保存集合键 member1, member2, ..., memberN = get_member_from_set(key) f.write_command(&quot;SADD &quot; + key + member1 + member2 + ... + memberN) elif key.type == Hash: # 用 HMSET key field1 value1 field2 value2 ... fieldN valueN 命令来保存哈希键 field1, value1, field2, value2, ..., fieldN, valueN =\\ get_field_and_value_from_hash(key) f.write_command(&quot;HMSET &quot; + key + field1 + value1 + field2 + value2 +\\ ... + fieldN + valueN) elif key.type == SortedSet: # 用 ZADD key score1 member1 score2 member2 ... scoreN memberN # 命令来保存有序集键 score1, member1, score2, member2, ..., scoreN, memberN = \\ get_score_and_member_from_sorted_set(key) f.write_command(&quot;ZADD &quot; + key + score1 + member1 + score2 + member2 +\\ ... + scoreN + memberN) else: raise_type_error() # 如果键带有过期时间，那么用 EXPIREAT key time 命令来保存键的过期时间 if key.have_expire_time(): f.write_command(&quot;EXPIREAT &quot; + key + key.expire_time_in_unix_timestamp()) # 关闭文件 f.close() aof子线程重写 aof子线程重写原因 aof_rewrite函数创建新文件并进行大量写入操作，调用这个函数的线程将被长时间的阻塞 Redis服务器使用单线程来处理命令请求，如果直接是服务器进程调用AOF_REWRITE函数的话，重写AOF期间，服务器将无法处理客户端发送来的命令请求 Redis不希望AOF重写会造成服务器无法处理请求，所以Redis决定将AOF重写程序放到子进程（后台）里执行。 使用子进程进行AOF重写的问题 子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致。 解决数据不一致问题 Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用 Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区 当子进程完成对AOF文件重写之后，会向父进程发送一个完成信号，父进程接到该完成信号之后，会调用一个信号处理函数 将AOF重写缓存中的内容全部写入到新的AOF文件中；这个时候新的AOF文件所保存的数据库状态和服务器当前的数据库状态一致； 新的AOF文件进行改名，原子的覆盖原有的AOF文件；完成新旧两个AOF文件的替换。 主从复制全量同步 从服务器连接主服务器，发送SYNC命令； 主服务器接收到SYNC命名后，开始执行BGSAVE命令子线程生成RDB文件并使用缓冲区记录此后执行的所有写命令； 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 增量同步 Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令 Redis主从同步策略主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。 主从同步存在的问题 数据不一致，网络传输延迟，读数据读取从库 读取过期时间的key,从库读取,3.2之前的不检查过期, 会返回数据, 3.2之后虽然不删除过期数据, 但是返回空值 主从切换切换方式 手动切换 手动将从节点设置成主节点。命令：redis-cli -h &lt;从节点ip&gt; -p &lt;从节点端口号&gt; slaveof no one 哨兵模式 Sentinel实例可以自动的将主节点下的其中一个从节点升级为新的主节点 Sentinel实例会不断检测主从节点是否正常运 当某个节点出现异常宕机时，Sentinel实例会向管理员或者其他应用发送提醒 当主节点宕机时，Sentinel实例会将该主节点下的其中一个从节点升级为新的主节点，并且原先其他从节点重新发起socket请求成为新的主节点的从节点 向客户端返回新主节点的地址，就可以正常上使用新的主节点来处理请求 哨兵模式只开启一个Sentinel实例进行监视，容易出现问题，一般情况下会开启多个Sentinel实例进行监控，一般情况下至少需要3个Sentinel实例。主节点宕机状态 - 只有一个哨兵认为这个主节点宕机了，则成为主观宕机。 - 如果达到一定数量的节点认为该主节点宕机，则成为客观宕机。 为什么至少需要3个Sentinel实例？ 当指定时间内一定哨兵数量（哨兵数量 / 2 + 1）都认为主节点宕机则称为客观宕机，如果数量为2，出现一个哨兵宕机的情况，在需要主从切换的时候因为无法达到认为主节点宕机的哨兵数量为2，所以在主节点出现宕机时无法进行主从切换。所以说部署哨兵至少需要3个Sentinel实例来保证健壮性。 哨兵模式引发数据丢失问题哨兵模式 + Redis主从复制这种部署结构，无法保证数据不会出现丢失。哨兵模式下数据丢失主要有两种情况：因为主从复制是异步操作，可能主从复制还没成功，主节点宕机了。这时候还没成功复制的数据就会丢失了。如果主节点无法与其他从节点连接，但是实际上还在运行。这时候哨兵会将一个从节点切换成新的主节点，但是在这个过程中实际上主节点还在运行，所以继续向这个主节点写入的数据会被丢失。 解决数据丢失方案使用命令：min-slaves-to-write 1min-slaves-max-lag 10使用这组命令可以设置至少有一个从节点数据复制延迟不能超过10S，也就是说如果一个直接点下所有从节点数据复制延迟都超过10S，则停止主节点继续接收处理新的请求。这样可以保证数据丢失最多只会丢失10S内的数据。 redis 持久化方案数据库的恢复服务器启动时，如果没有开启AOF持久化功能，则会自动载入RDB文件，期间会阻塞主进程。如果开启了AOF持久化功能，服务器则会优先使用AOF文件来还原数据库状态，因为AOF文件的更新频率通常比RDB文件的更新频率高，保存的数据更完整。 RDB持久化 RDB持久化即通过创建快照（压缩的二进制文件）的方式进行持久化，保存某个时间点的全量数据。RDB持久化是Redis默认的持久化方式。 触发方式 手动触发 save， 在命令行执行save命令，将以同步的方式创建rdb文件保存快照，会阻塞服务器的主进程，生产环境中不要用 bgsave, 在命令行执行bgsave命令，将通过fork一个子进程以异步的方式创建rdb文件保存快照，除了fork时有阻塞，子进程在创建rdb文件时，主进程可继续处理请求 自动触发 在redis.conf中配置 save m n 定时触发，如 save 900 1表示在900s内至少存在一次更新就触发 主从复制时，如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点 执行debug reload命令重新加载Redis时 执行shutdown且没有开启AOF持久化 redis.conf中RDB持久化配置12345678910# 只要满足下列条件之一，则会执行bgsave命令save 900 1 # 在900s内存在至少一次写操作save 300 10save 60 10000# 禁用RBD持久化，可在最后加 save &quot;&quot;# 当备份进程出错时主进程是否停止写入操作stop-writes-on-bgsave-error yes # 是否压缩rdb文件 推荐no 相对于硬盘成本cpu资源更贵rdbcompression no AOF持久化AOF（Append-Only-File）持久化即记录所有变更数据库状态的指令，以append的形式追加保存到AOF文件中。在服务器下次启动时，通过载入和执行AOF文件中保存的命令，来还原服务器关闭前的数据库状态。 redis.conf中AOF持久化配置如下 123456789101112131415# 默认关闭AOF，若要开启将no改为yesappendonly no# append文件的名字appendfilename &quot;appendonly.aof&quot;# 每隔一秒将缓存区内容写入文件 默认开启的写入方式appendfsync everysec # 当AOF文件大小的增长率大于该配置项时自动开启重写（这里指超过原大小的100%）。auto-aof-rewrite-percentage 100# 当AOF文件大小大于该配置项时自动开启重写auto-aof-rewrite-min-size 64mb AOF持久化的实现包括3个步骤: 命令追加：将命令追加到AOF缓冲区文件写入：缓冲区内容写到AOF文件文件保存：AOF文件保存到磁盘其中后两步的频率通过appendf sync来配置，appendfsync的选项包括 always， 每执行一个命令就保存一次，安全性最高，最多只丢失一个命令的数据，但是性能也最低（频繁的磁盘IO）everysec，每一秒保存一次，推荐使用，在安全性与性能之间折中，最多丢失一秒的数据no， 依赖操作系统来执行（一般大概30s一次的样子），安全性最低，性能最高，丢失操作系统最后一次对AOF文件触发SAVE操作之后的数据 RDB vs AOFRDB与AOF两种方式各有优缺点。 RDB的优点：与AOF相比，RDB文件相对较小，恢复数据比较快（原因见数据恢复部分）RDB的缺点：服务器宕机，RBD方式会丢失掉上一次RDB持久化后的数据；使用bgsave fork子进程时会耗费内存。 AOF的优点： AOF只是追加文件，对服务器性能影响较小，速度比RDB快，消耗内存也少，同时可读性高。AOF的缺点：生成的文件相对较大，即使通过AOF重写，仍然会比较大；恢复数据的速度比RDB慢。 数据恢复 RDB、AOF混合持久化Redis从4.0版开始支持RDB与AOF的混合持久化方案。首先由RDB定期完成内存快照的备份，然后再由AOF完成两次RDB之间的数据备份，由这两部分共同构成持久化文件。该方案的优点是充分利用了RDB加载快、备份文件小及AOF尽可能不丢数据的特性。缺点是兼容性差，一旦开启了混合持久化，在4.0之前的版本都不识别该持久化文件，同时由于前部分是RDB格式，阅读性较低。 开启混合持久化 aof-use-rdb-preamble yes 数据恢复加载过程就是先按照RDB进行加载，然后把AOF命令追加写入。 持久化方案的建议Redis只用来做缓存服务器，比如数据库查询数据后缓存，可以不用考虑持久化，因为缓存服务失效还能再从数据库获取恢复。提供很高的数据保障性，建议你同时使用两种持久化方式。如果可以接受灾难带来的几分钟的数据丢失，那么可以仅使用RDB。通常的设计思路是利用主从复制机制来弥补持久化时性能上的影响。即Master上RDB、AOF都不做，保证Master的读写性能，而Slave上则同时开启RDB和AOF（或4.0以上版本的混合持久化方式）来进行持久化，保证数据的安全性。","categories":[{"name":"redis","slug":"redis","permalink":"https://blog.imder.top/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://blog.imder.top/tags/redis/"}]},{"title":"jm调优","slug":"\bJM调优","date":"2022-03-08T09:00:00.000Z","updated":"2024-03-28T16:43:20.059Z","comments":true,"path":"2022/03/08/\bJM调优/","link":"","permalink":"https://blog.imder.top/2022/03/08/%08JM%E8%B0%83%E4%BC%98/","excerpt":"","text":"jm调优遇到了什么问题需要调优？生产环境新上线了一个系统，莫名其妙奔溃，错误日志报异常OOM 类加载过程加载 -&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化 -&gt; 使用 -&gt; 卸载 什么情况下会去加载一个类呢?何时将“.class”字节码文件中加载这个类到JVM内存里来，代码中用到这个类的时候。 验证来校验加载进来的“.class”文件中的内容，是否符合指定的jvm规范。 准备类的类变量(static修饰的变量)分配内存空间，来一个默认的初始值，并非执行赋值 解析阶段符号引用替换为直接引用 初始化执行类变量的赋值语句，执行静态代码块 类加载器和双亲委派机制类加载器 启动类加载器Bootstrap ClassLoader，负责加载Java安装目录下的“lib”目录中的核心类库 扩展类加载器Extension ClassLoader，负责加载Java安装目录“lib\\ext”目录里面有一些类 应用程序类加载器Application ClassLoader，负责去加载“ClassPath”环境变量所指定的路径中的类 理解为去加载自己写好的Java代码 自定义类加载器 除了上面那几种之外，还可以自定义类加载器，去根据自己的需求加载自己的类。双亲委派机制 JVM的类加载器是有亲子层级结构的，启动类加载器是最上层的，扩展类加载器在第二层，第三层是应用程序类加载器，最后一层是自定义类加载器。 双亲委派模型:先找父亲去加载，不行的话再由自己来加载。 内存划分方法区（1.8之前） 元空间将“.class”文件里加载进来的类 程序计数器写好的Java代码会被翻译成字节码，对应各种字节码指令，JVM加载类信息到内存之后，会使用自己的字节码执行引擎执行字节码指令，执行时，JVM里就需要一个特殊的内存区域，那就是“程序计数器”，这个程序计数器就是用来记录当前执行的字节码指令的位置的 Java虚拟机栈 JVM必须有一块区域是来保存每个方法内的局部变量等数据的，这个区域就是Java虚拟机栈 每个线程都有自己的Java虚拟机栈 如果线程执行了一个方法，就会对这个方法调用创建对应的一个栈帧，栈帧里就有这个方法的局部变量表 、操作数栈、动态链接、方法出口 Java堆内存存放代码中创建的各种对象的 jvmjvm参数 -Xms:Java堆内存的大小 、-Xmx:Java堆内存的最大大小 -Xms和-Xmx，分别用于设置Java堆内存的刚开始的大小，以及允许扩张到的最大大小。 -Xmn:Java堆内存中的新生代大小，扣除新生代剩下的就是老年代的内存大小,默认不设置新生代大小时，大概老年代占2/3，新生代占1/3，eden和2个survivor 8:1:1 jvm参数”- XX:SurvivorRatio=8” -XX:PermSize:永久代大小、-XX:MaxPermSize:永久代最大大小 jdk1.8 用这两个-XX:MetaspaceSize和-XX:MaxMetaspaceSize替换永久代大小 -Xss:每个线程的栈内存大小 如何合理设置永久代大小?一般你设置个几百MB，大体上都是够用的 因为里面主要就是存放一些类的信息 如何合理设置栈内存大小一般默认就是比如512KB到1MB 如何确定对象是垃圾？可达性分析算法GCRoot根由那些对象组成？对象无引用时会被确定为垃圾对象，方法的局部变量、类的静态变量都被看为GCRoot根 垃圾对象一定会被回收吗？不一定，如果对象重写了Object类中的finialize()方法，并且在该方法建立起与静态变量的引用关系就可以不被回收 强引用、软引用、弱引用、虚引用强引用：绝对不能回收的对象软引用：有的对象可有可无，如果内存实在不够了，可以回收他。弱引用：与没引用是类似的，如果发生垃圾回收，就会把这个对象回收掉虚引用：暂时忽略，很少用。 垃圾回收算法复制算法：内存区域划分为两块，对象就就会分配在其中一块内存空间，垃圾回收时，存活对象复制到另一块内存空间，同时原分配对象空间清除所有对象缺点：内存使用率太低 优点：不会产生内存碎片，不浪费内存空间 复制算法做出如下优化： 把新生代内存区域划分为三块:1个Eden区，2个Survivor区，其中Eden区占80%内存空间，每一块Survivor区各占10%内存空间 刚开始对象都是分配在Eden区内的，如果Eden区快满了，此时就会触发垃圾回收，把Eden区中的存活对象都一次性转移到一块空着的Survivor区，接着Eden区就会被清空 然后再次分配新对象到Eden区里，此时，Eden区和一块Survivor区里是有对象的，其中Survivor区里放的是上一次Minor GC后存活的对象。如果下次再次Eden区满，那么再次触发Minor GC，Eden区和放着上一次Minor GC后存活对象的Survivor区内的存活对象，转移到另外一块Survivor区去。然后清空eden区和上一次的survivor区 对象何时从新生代转到老年代？ 15次minor gc对象还存活。JVM参数“-XX:MaxTenuringThreshold”来设置，默认是15岁 动态对象年龄判断：假如说当前放对象的Survivor区域的一些对象大小和（按照年龄排正序）大于了这块Survivor区域的内存大小的50%，那么此时大于等于这批对象年龄的对象，就可以直接进入老年代。年龄1+年龄2+年龄n的多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n以上的对象都放入老年代。 大对象直接进入老年代。JVM参数，“-XX:PretenureSizeThreshold”，单位字节数，比如“1048576”字节，就是1MB。 Minor GC后的对象太多无法放入Survivor区怎么办? 这个时候就必须得把这些对象直接转移到老年代去 老年代空间分配担保机制 在执行任何一次Minor GC之前，JVM会先检查一下老年代可用的可用内存空间，是否大于新生代所有对象的总大小。避免Minor GC后老年代空间放不下存活对象 如果老年代的内存大小是大于新生代所有对象的，此时就可以对新生代发起一次Minor GC了 如果老年代的内存大小是小于新生代所有对象的，JVM“-XX:- HandlePromotionFailure”的参数是否设置, 未设置 发生一次Full GC（对老年代进行垃圾回收，同时一般会对新生代进行垃圾回收） 设置表示开启老年代空间担保，接着判断老年代的内存大小，是否大于之前每一次Minor GC后进入老年代的对象的平均大小，如果大于，则Minor GC,如果小于，FullGC（年轻代+老年代+永久代） 如果要是Full GC过后，老年代还是没有足够的空间存放Minor GC过后的剩余存活对象，就会导致所谓的 “OOM”内存溢出 老年代采用的什么垃圾回收算法？ 标记整理算法：首先标记出来老年代当前存活的对象，接着会让这些存活对象在内存里进行移动，把存活对象尽量都挪动到一边去 老年代的垃圾回收算法的速度至少比新生代的垃圾回收算法的速度慢10倍。 如果系统频繁出现老年代的Full GC垃圾回收，会导致系统性能被严重影响，出现频繁卡顿的情况。垃圾收集器 Serial和Serial Old垃圾回收器:分别用来回收新生代和老年代的垃圾对象，工作原理就是单线程运行，STW，一般几乎不用。 ParNew和CMS垃圾回收器:ParNew现在一般用在新生代的，CMS是用在老年代的，都是多线程并发的机制，性能更好，一般是生产系统的标配组合。 G1垃圾回收器:统一收集新生代和老年代，采用了更加优秀的算法和设计机制 stw直接停止Java系统的所有工作线程，让代码不再运行，让垃圾回收线程可以专心致志的进行垃圾回收的工作 - 假设我们的Minor GC要运行100ms，那么可能就会导致系统直接停顿100ms不能处理任何请求 - Full GC是最慢的，有的时候弄不好一次回收要进行几秒钟，甚至几十秒，有的极端场景几分钟都是有可能的。一旦频繁的Full GC，系统每一段时间就卡死个30秒吗? - 无论是新生代GC还是老年代GC，都尽量不要让频率过高，避免持续时间过长 ParNew垃圾收集器暂停系统程序的工作线程，禁止程序继续运行创建新的对象，用多个垃圾回收线程去进行垃圾回收，用复制算法回收使用ParNew垃圾回收器 JVM参数 -XX:+UseParNewGCParNew垃圾回收器默认情况下的线程数量 垃圾回收线程的数量就是跟CPU的核数是一样。 JVM参数设置 - XX:ParallelGCThreads=n 服务器模式与客户端模式 启动系统的时候是可以区分服务器模式和客户端模式的，启动系统的时候加入“-server”就是服务器模式，如果加入“-cilent”就是客户端模式。 系统部署在比如4核8G的Linux服务器上那么就应该用服务器模式，如果你的系统是运行在比如Windows上的客户端程序，那么就应该是客户端模式。 服务器模式通常ParNew来进行垃圾回收，客户端模式使用采用Serial垃圾回收器，单CPU单线程垃圾回收 CMSCMS垃圾回收器采取的是垃圾回收线程和系统工作线程尽量同时执行的模式来处理的，使用标记-清理的算法初始标记 ：stw 很快，仅仅标记出GC Root根并发标记 ：对老年代所有对象进行GC Roots追踪，其实是最耗时的重新标记 ：stw 很快,对在第二阶段中被系统程序运行变动过的少数对象进行标记并发清理 ：很耗时 缺点： - 会消耗CPU资源，在并发标记时，老年代存活对象多，追踪大量对象，耗时较高，并发清理，把垃圾对象从随机的内存位置清理掉，也比较耗时，CMS的垃圾回收线程是比较耗费CPU资源的。CMS默认启动的垃圾回收线程的数量是(CPU核数 + 3)/ 4。 - 会产生浮动垃圾，并发清理同时随着系统运行让一些对象进入老年代，这种垃圾需要等到下一次GC才能回收掉 -XX:CMSInitiatingOccupancyFaction 用来设置老年代占用多少时触发CMS垃圾回收，JDK 1.6里面默认的值是 92%。-XX:+UseCMSCompactAtFullCollection 默认开启 Full GC之后再次进行stw，碎片整理-XX:CMSFullGCsBeforeCompaction 执行多少次Full GC之后执行一次内存碎片整理，默认是0，每次Full GC之后都会进行内存整理。 优化方案 评估Eden区进行Minor Gc 之后存活的对象大小，Suvivor区空间够不够，建议的是调整新生代和老年代的大小，让短期存活的对象在新生代就被垃圾回收 结合系统的运行模型，@Service、@Controller之类的注解那种需要长期存活的核心业务逻辑组件，降低“-XX:MaxTenuringThreshold”参数的值，避免对长期存活的对象在新生代Survivor区来回复制 大对象直接进入老年代，-XX:PretenureSizeThreshold=1M，避免对象在新生代Survivor区来回复制一般启动参数： Xms3072M -Xmx3072M -Xmn2048M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M - XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M -XX:+UseParNewGC - XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 Concurrent Mode FailureCMS在垃圾回收的时候，尤其是并发清理期间，系统程序是可以并发运行的，假设此时老年代空闲空间仅剩100MB，此时系统程序还在不停的创建对象，万一这个时候系统运行触发了某个条件，比如说有200MB对象要进入老年代，这个时候就会触发“Concurrent Mode Failure”问题，因为此时老年代没有足够内存来放这200MB对象，此时就会导致立马进入Stop the World，然后切换CMS为Serial Old收集器来单线程收集垃圾 G1 垃圾收集器（针对大内存机器通常建议采用G1垃圾回收器） G1垃圾回收器把Java堆内存拆分为多个大小相等的Region，G1会有新生代和老年代的概念，但是只是逻辑上的概念 G1垃圾回收器可以设置一个垃圾回收的预期停顿时间 G1通过把内存拆分为大量小Region，以及追踪每个Region中可以回收的对象大小和预估时间，在垃圾回收的时候，尽量把垃圾回收对系统造成的影响控制在指定的时间范围内，同时在有限的时间内尽量回收尽可能多的垃圾对象 使用“-XX:+UseG1GC”来指定使用G1垃圾回收器，会自动用堆大小除以2048得到每个region的大小，可以使用-XX:G1HeapRegionSize指定region的大小G1中新生代（Eden、Survivor）、老年代的逻辑概念，-XX:G1NewSizePercent来设置新生代初始占比的，随着对象的不停创建，属于新生代的Region会不断增加，Eden和Survivor对应的Region也会不断增加。一旦新生代达到了设定的占据堆内存的最大大小60%，会触发新生代的GC，G1就会用复制算法来进行垃圾回收，进入一个“Stop the World”状态，然后把Eden对应的Region中的存活对象放入S1对应的Region中，接着回收掉Eden对应的Region中的垃圾对象 G1是可以设定目标GC停顿时间的，G1执行GC的时候最多可以让系统停顿多长时间，可以通过“-XX:MaxGCPauseMills”参数来设定，默认值是200ms。 年轻代何时进入老年代？跟之前几乎是一样的 对象在新生代gc多次仍然存活 -XX:MaxTenuringThreshold 年龄为1岁，2岁，3岁，n岁的对象的大小总和超过了Survivor的50%，n+1岁进入老年代 在G1中，大对象的判定规则：一个大对象超过了一个Region大小的50%，会被放入大对象专门的Region G1有“-XX:InitiatingHeapOccupancyPercent”，默认值是45%：老年代占据了堆内存的45%的Region的时候，尝试触发一个新生代+老年代一起回收的混合回收阶段。 G1垃圾收集几个阶段（混合回收可以执行多次） 初始标记 stw 标记一下GC Roots直接能引用的对象 很快 并发标记，允许系统程序的运行，同时进行GC Roots追踪，从GC Roots开始追踪所有的存活，同时记录并发标记系统运行导致哪些对象的改变 最终标记阶段，stw 对并发标记阶段记录的对象进行标记，最终标记一下有哪些存活对象，有哪些是垃圾对象 混合回收，从新生代和老年代里都回收一些Region，先停止工作，执行一次混合回收回收掉一些Region，接着恢复系统运行，然后再次停止系统运行，再执行一次混合回收回收掉一些Region。-XX:G1MixedGCCountTarget 混合回收的过程中，最后一个阶段执行几次混合 回收，默认值是8次 G1调优 -Xms4096M -Xmx4096M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseG1GC -XX:G1NewSizePercent参数是用来设置新生代初始占比的，不用设置，维持默认值为5%即可 -XX:G1MaxNewSizePercent参数是用来设置新生代最大占比的，也不用设置，维持默认值为60%即可 -XX:MaxGCPauseMills 默认值是200毫秒 垃圾回收时最大停顿时间 G1里是很动态灵活的，根据你设定的gc停顿时间给你的新生代不停分配更多Region，到一定程度，就会触发新生代gc，保证新生代gc的时候导致的系统停顿时间在预设范围内。 新生代的GC优化：合理设置“-XX:MaxGCPauseMills”参数，设置小了，Gc频繁，设置大了，GC停顿时间长 mixed gc优化：默认老年代占据了堆内存的45%的Region的时候，发生Gc,如果-XX:MaxGCPauseMills设置过大，就会导致新生代GC后更多的对象进入老年代，加速mixed gc 发生 日处理上亿数据案例 分布式系统，4核心8G，JVM给了4G，新生代和老年代各1.5G（1.2G Eden区Survivor区150M）,每台机器每分钟计算100条数据，每秒取10000条数据，需要10秒计算完成 预估每条数据20个字段，每个字段4B，大约1条数据100B,10000条数据1M，系统运行产生其他对象*10，10M 每次运行产生10M，一分钟产生1G，大概1分钟就要产生一次年轻代垃圾 每次年轻代垃圾回收，会有大概17～20次还在计算中，这些数据都是存活的对象，占用空间170M～200M 每次年轻代垃圾回收，Survivor区无法放入存活的对象，放老年代，在7～9次年轻代垃圾回收后，老年代就满了，触发Fullgc 耗时 将年轻代分配2G eden1.6G surviro 200m BI系统案例 10台机器来部署BI系统，4核8G的配置，堆内存中的新生代分配的内存都在1.5G左右，Eden区大概也就1G左右的空间，几万商家作为你的系统用户，很可能同一时间打开那个实时报表的商家就有几千个，然后每个商家打开实时报表之后，前端页面都会每隔几秒钟发送请求到后台来加载最新数据BI系统部署的每台机器每秒的请求会达到几百个，假设5000个商家同时在线，每秒刷新一次，每秒5000个请求，每台机器分摊500个请求 预算每个请求大概需要加载出来10kb的数据进行计算，每秒需要加载出来5MB的数据到内存中进行计算 200s 就会触发年轻代GC，存活的对象估计几十m 估计50次年轻代gc 会发生老年代Gc 每秒十万并发，那么就要部署上百台机器来，扩大机器内存，使用G1收集器，采用10台机器 实战打印gc日志 -XX:+PrintGCDetils:打印详细的gc日志 -XX:+PrintGCTimeStamps:这个参数可以打印出来每次GC发生的时间 -Xloggc:gc.log:这个参数可以设置将gc日志写入一个磁盘文件 Jvm 命令 jps 查看jvm进程ID jstat -gc jvm进程ID 查看jvm进程内存使用情况 S0C:From Survivor区的大小 S1C:To Survivor区的大小 S0U:From Survivor区当前使用的内存大小 S1U:To Survivor区当前使用的内存大小 EC:Eden区的大小 EU:Eden区当前使用的内存大小 OC:老年代的大小 OU:老年代当前使用的内存大小 MC:方法区(永久代、元数据区)的大小 MU:方法区(永久代、元数据区)的当前使用的内存大小 YGC:Young GC次数 YGCT:Young GC的耗时 FGC:Full GC次数 FGCT:Full GC的耗时 GCT:所有GC的总耗时 jstat -gc jvm进程ID 1000 10 1秒输出一次 输出10次 用于观察环境上内存变化 jmap -heap jvm进程ID 查看堆内存信息 jmap -histo:live jvm进程ID 查看内存对象信息 jmap -dump:live,file=/filename.hprof jvm进程ID dump出内存信息 jhat -port 7000 filename.hprof 将dump文件加载出来以网页方式呈现 调优调优方案尽量让每次Young GC后的存活对象小于Survivor区域的50%，都留存在年轻代里。尽量别让对象进入老年代。尽量减少Full GC的频率，避免频繁Full GC对JVM性能的影响。 社交app，QPS 十万 老年代频繁Gc 压缩碎片，避免每次GC间隔越来越短 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=5垂直电商app 每小时总会有卡顿 垂直电商APP的各个系统通过jstat分析JVM GC之后发现，基本上高峰期的时候，Full GC每小时都会发生好几次 通用JVM参数 -Xms4096M -Xmx4096M -Xmn3072M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseParNewGC - XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=92 -XX:+UseCMSCompactAtFullCollection - XX:CMSFullGCsBeforeCompaction=0 优化fullgc的效率 -XX:+CMSParallelInitialMarkEnabled CMS垃圾回收器的“初始标记”阶段开启多线程并发执行 -XX:+CMSScavengeBeforeRemark 会在CMS的重新标记阶段之前，尽量执行一次Young GC。 频繁的fullgc 观察后发现元空间的满了 代码里写了大量反射代码，JVM会动态的去生成一些类放入Metaspace区域里的，JVM自己创建的奇怪的类Class对象是SoftReference 软引用，只有内存不够才会回收，怎么判断要不要回收？clock - timestamp &lt;= freespace * SoftRefLRUPolicyMSPerMB，clock - timestamp代表了一个软引用对象他有多久没被访问过了，freespace代表JVM中的空闲内存空间，SoftRefLRUPolicyMSPerMB代表每一MB空闲内存空间可以允许SoftReference对象存活多久 SoftRefLRUPolicyMSPerMB 设置为0 导致 在有大量反射代码的场景下 -XX:SoftRefLRUPolicyMSPerMB=0 可以设置个1000，2000，3000，或者5000毫秒 默认1000 线上fullgc频繁 机器配置:2核4G，JVM堆内存大小:2G，系统运行时间:6天，系统运行6天内发生的Full GC次数和耗时:250次，70多秒，系统运行6天内发生的Young GC次数和耗时:2.6万次，1400秒，每天会发生4000多次Young GC，每分钟会发生3次，每次Young GC在50毫秒左右 未优化前 -Xms1536M -Xmx1536M -Xmn512M -Xss256K -XX:SurvivorRatio=5 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC - XX:CMSInitiatingOccupancyFraction=68 -XX:+CMSParallelRemarkEnabled -XX:+UseCMSInitiatingOccupancyOnly - XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC 通过jstat的观察，每次Young GC过后升入老年代里的对象很少 ， 每次Young GC过后大概就存活几十MB而已，那么Survivor区域因为就70MB，所以经常会触发动态年龄判断规则，导致偶尔一次Young GC过后有几十MB对象进入老年代 大对象 jstat工具观察系统，发现老年代里突然进入了几百MB的大对象,就是特殊场景全表查了数据库，量比较大 优化方案 去除查大数据量的bug 年轻代变大，避免触发动态年龄判断，部分垃圾对象进入老年代 -Xms1536M -Xmx1536M -Xmn1024M -Xss256K -XX:SurvivorRatio=5 -XX:PermSize=256M -XX:MaxPermSize=256M - XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 - XX:+CMSParallelRemarkEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:+PrintGCDetails -XX:+PrintGCTimeStamps - XX:+PrintHeapAtGC线上fullgc每秒一次 排查是不是代码里使用System.gc()会指挥JVM去尝试执行一次Full GC 推荐使用参数禁用-XX:+DisableExplicitGC 不允许通过代码触发GC mat 内存泄漏分析利器 频繁Full GC的原因： 内存分配不合理，导致对象频繁进入老年代，进而引发频繁的Full GC; 存在内存泄漏等问题，就是内存里驻留了大量的对象塞满了老年代，导致稍微有一些对象进入老年代就会引发Full GC; 永久代里的类太多，触发了Full GC 大促系统 突然卡顿严重 线程太多 负载重 JVM fullgc jstat 分析得出fullgc频繁 jstat -gc pid 1000 1000 jmap -dump:live,file=/data.hprof pid dump文件导入visualvm可视化图形界面分析 mat工具分析 https://www.eclipse.org/mat/downloads.php MAT上有一个工具栏，Leak Suspects，内存泄漏的分析 处理数据量巨大的系统前端页面卡顿 jstat -gc pid 1000 1000 发现fullgc 耗时10s 堆分配了20G的内存，其中10G给了年轻代，10G给了老年代 Eden区大概1分钟左右就会塞满，young gc 每次都会有几个g进入老年代 系统运行的时候在产生大量的对象，而且处理的极其的慢 调优到底该怎么做 原则:尽可能让每次Young GC后存活对象远远小于Survivor区域，避免对象频繁进入老年代触发Full GC。 新上线系统进行压测，模拟生产环境压力，用jstat观察jvm内存变化 频繁gc表现： 机器cpu负载过高 fullgc报警 无法处理请求或者响应慢 频繁gc的原因 一次性加载过多数据进入内存，很多大对象，导致大对象进入老年代 打内存快照 mat分析 系统高并发导致频繁young gc，每次young gc 存活的对象太多，内存分配不合理，survivor区太小，导致对象进入老年代，频繁触发fullgc jstat观察，然后调大survivor区，调大年轻代 永久代因为加载类过多触发fullgc 打内存快照 mat分析 调用System.gc() 代码优化 内存泄漏，无法被回收 代码优化 应该如何在面试中回答JVM生产优化问题? 归纳总结出来一套通用的方法付论 堆内存大小设置 -Xms3G -Xmx3G 最大最小堆设置相同，避免内存伸缩时造成gc导致卡顿 -Xmn2G 设置新生代的大小 -XX:SurvivorRatio=8设置eden与survivor区比例 元空间 -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m gc日志 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:/gc.log 栈大小 -Xss1M 垃圾收集器设置 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseG1GC 垃圾收集器相关参数设置 -XX:CMSInitiatingOccupancyFaction=92 cms老年代内存大小发生fullgc,可以设置稍微小，降低发生fullgc的时间 -XX:+UseCMSCompactAtFullCollection - XX:CMSFullGCsBeforeCompaction=0 压缩碎片，每次都压缩吗 -XX:+CMSParallelInitialMarkEnabled CMS垃圾回收器的“初始标记”阶段开启多线程并发执行 -XX:+CMSScavengeBeforeRemark 会在CMS的重新标记阶段之前，尽量执行一次Young GC -XX:+UseCMSInitiatingOccupancyOnly 只使用指定的值，避免伸缩 oom的参数设置 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/app/oom 预防System.gc() -XX:+DisableExplicitGC 不容许代码控制gc 负责的系统，假设数据量和访问量暴增10倍，或者100倍，此时会不会出现频繁Full GC的 问题?如果会的话，那么一旦发生了，如何定位、分析和解决? 负责的系统主要的业务借款，用户量大概有2000万，日活500万，集中在下午4～6点会进行借款 目前生产机器4核8G配置给jvm4G 借款的接口并发 每秒进入借款页面5000，借款相关接口并发10000 核心接口 产生新对象平均20 字段数平均20个 420B20=2k 扩大10倍～20倍 20k 部署8台机器 接口并发1000接口/s 一秒产生20m对象 平均80s就会young gc一次 说自己的系统可能在哪些情况下发生频繁Full GC，在压测的时候就发现了这 些问题，然后你是如何进行JVM性能优化的! oom 元空间 -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m 元空间gc的条件：类的类加载器先要被回收，类的所有对象实例都要被回收 在上线系统的时候对Metaspace区域直接用默认的参数,默认的太小 用cglib之类的技术动态生成一些类，一旦代码中没有控制好，导致生成的类过多，导致元空间满，从而引发oom 栈内存 递归调用 堆内存 高并发场景，导致ygc后很多请求还没处理完毕，存活对象太多，可能就在Survivor区域放不下了，只能进入到老年代，老年代很快就会放满。又有一批对象生成后younggc后仍有大量存活对象，需要放到老年代，此时老年代满了，就要触发fullgc,fullgc之后仍然放不下对象就会oom 大型计算系统oom了 从数据存储系统读出并计算，计算完成推送Kafka 发送Kafka失败就要重试 假设Kafka宕机，系统计算结果越来越多，最终oom 解决方案，当Kafka宕机时，写本地存储 oom监控方案 主动监控：监控系统，监控cpu,内存，监控fullgc次数 被动监控： 系统宕机，通知 每天观察系统日志系统宕机时dump XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/app/oom netty nio 堆外内存溢出当堆外内存都被大量的DirectByteBuffer对象关联使用了，再要使用更多的堆外内存，那么就会报内存溢出了系统承载的是超高并发，复杂压力很高，瞬时大量请求过来，创建了过多的DirectByteBuffer占用了大量的堆外内存，此时再继续想要使用堆外内存，就会内存溢出 rpc oomrpc传输需要将对象序列化成字节，比如服务A的Request类有15个字段，序列化成字节流给你发送过来了，服务B的Request类只有10个字段，有的字段名字还不一 样，那么反序列化的时候就会失败，代码中写的逻辑是，一旦反序列化失败了，此时就会开辟一个byte[]数组，默认大小是4GB，然后把对方的字节流原封不动的放进 去。垃圾处理逻辑，序列化失败应该返回错误的响应码","categories":[{"name":"JAVA虚拟机","slug":"JAVA虚拟机","permalink":"https://blog.imder.top/categories/JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA/"}],"tags":[{"name":"JAVA虚拟机","slug":"JAVA虚拟机","permalink":"https://blog.imder.top/tags/JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"学MQ所得","slug":"学MQ所得","date":"2022-02-28T22:22:22.000Z","updated":"2024-03-28T16:43:20.075Z","comments":true,"path":"2022/02/28/学MQ所得/","link":"","permalink":"https://blog.imder.top/2022/02/28/%E5%AD%A6MQ%E6%89%80%E5%BE%97/","excerpt":"","text":"梳理出来自己负责的系统的核心业务流程，核心功能模块，跟其他系统是如何交互的，数据是如何存储，当前已经使用了哪些中间件技术。系统与系统之间的耦合性体现来思考一个问题，假设促销系统现在有一个接口，专门是让你调用了以后派发优惠券的，现在这个接口接收的参数有 5个，你要是调用这个接口，就必须给他传递5个参数过去，这个是没的说的。现在问题来了，负责促销系统的工程师某一天突然有一个新的想法，他希望改一改这个接口，在接口调用的时候需要传递7个参数！一旦他的这个新接口上线了，你还是给他传5个参数，那么他那里就会报错，这个派发优惠券的行为就会失败！那在这样的一个情况下应该怎么办？ 很简单，你作为订单系统的负责人，必须要配合促销系统去修改代码，既然他要7个参数，那么你就必须得在代码里调用他的接口的时候传递7个参数。并且你还得配合他的新接口去进行测试以及部署上线，你必须得围绕着他转，配合他。在这种情况下，就说明你的订单系统跟促销系统是强耦合的 订单系统存在的问题 消息中间件异步化提升性能，降低系统耦合，流量削峰 解耦异步 引入MQ之前,a系统调用b系统 引入MQ之后 削峰 MQ这个技术抗高并发的能力远远高于数据库，同样的机器配置下，如果数据库可以抗每秒6000请求，MQ至少可以抗每秒几万请求。 MQ进行流量削峰的效果，系统A发送过来的每秒1万请求是一个流量洪峰，然后MQ直接给扛下来了，都存储自己本地磁盘，这个过程就是流量削峰的过程，瞬间把一个洪峰给削下来了，让系统B后续慢慢获取消息来处理。 kafka rabbitmq rocketmq kafka优点 Kafka的吞吐量几乎是行业里最优秀的，在常规的机器配置下，一台机器 可以达到每秒十几万的QPS Kafka性能也很高，发送消息给Kafka都是毫秒级的性能。 可用性也很高，Kafka是可以支持集群部署的，其中部分机器宕机是可以继续运行的。 kafka缺点 丢数据方面的问题，Kafka收到消息之后会写入一个磁盘缓冲区里，并没有直接落地到物理磁盘上去，要是机器本身故障，可能会导致磁盘缓冲区里的数据丢失。 功能非常的单一，主要是支持发送消息给他，然后从里面消费消息 kafka使用场景 Kafka用在用户行为日志的采集和传输上，比如大数据团队要收集APP上用户的一些行为日志，这种日志就是用Kafka来收集和传输的。 因为那种日志适当丢失数据是没有关系的，而且一般量特别大，要求吞吐量要高，一般就是收发消息，不需要太多的高级功能，所以Kafka是非常适合这种场景的。 RabbitMQ优点 保证数据不丢失 保证高可用性，集群部署的时候部分机器宕机可以继续运行 支持部分高级功 能，比如说死信队列，消息重试之类的 RabbitMQ缺点 RabbitMQ的吞吐量是比较低的，一般就是每秒几万的级别 集群扩展的时候（也就是加机器部署），还比较麻烦。 开发语言是erlang，国内很少有精通erlang语言的工程师，没办法去阅读他的源代码 RocketMQ 优点 RocketMQ是阿里开源的消息中间件，几乎同时解决了Kafka和RabbitMQ的缺陷。 RocketMQ的吞吐量很高，单机可以达到10万QPS以上 保证高可用性，性能很高，而且支持通过配置保证数据绝对不丢失，部署大规模的集群 支持各种高级的功能，比如说延迟消息、事务消息、消息回溯、死信队列、消息积压 RocketMQ是基于Java开发的，符合国内大多数公司的技术栈，可以阅读源码或者修改源码。 RocketMQ 缺点 RocketMQ的官方文档相对简单，但是Kafka和RabbitMQ的官方文档就非常的全面和详细，这可能是RocketMQ目前唯一的缺点。 活跃的社区和广泛的运用 基本上Kafka、RabbitMQ和RocketMQ的社区都还算活跃，更新频率都还可以，而且基本运用都非常的广泛。 目前Kafka几乎是国内大数据领域日志采集传输的标准,RabbitMQ在各种中小公司里运用极为广泛,RocketMQ也是开始在一些大公司和其他公司里快速推行中。 RocketMQ 相关问题 RocketMQ是如何集群化部署来承载高并发访问的？ 假设RocketMQ部署在一台机器上，即使这台机器配置很高，一般来说一台机器也就是支撑10万+的并发访问。 RocketMQ是可以集群化部署的，可以部署在多台机器上，假设每台机器都能抗10万并发，然后你只要让几十万请求分散到多 台机器上就可以了，让每台机器承受的QPS不超过10万不就行了 如果RocketMQ中要存储海量消息，如何实现分布式存储架构？ MQ会收到大量的消息，这些消息并不是立马就会被所有的消费方获取过去消费的，所以一般MQ都得把消息在自己本地磁盘存储起来，然后等待消费方获取消息去处理。 RocketMQ是如何分布式存储海量消息的呢？ 每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里 高可用保障:万一Broker宕机了怎么办？ Broker主从架构以及多副本策略 Master Broker收到消息后会同步给Slave Broker,这个时候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ的可靠性和高可用性 数据路由:怎么知道访问哪个Broker？ 有一个NameServer的概念，他也是独立部署在几台机器上的，然后所有的Broker都会把自己注册到NameServer上去，NameServer不就知道集群里有哪些Broker了？ RocketMQ NameServer设计原理 NameServer到底可以部署几台机器？ NameServer支持部署多台机器的,NameServer可以集群化部署的， 那为什么NameServer要集群化部署？ 最主要的一个原因，就是高可用性。 NameServer是集群里非常关键的一个角色，管理Broker信息，别人都要通过他才知道跟哪个Broker通信。 NameServer多机器部署，集群，高可用，保证任何一台机器宕机,其他机器上的NameServer可以继续对外提供服务 Broker在启动的时候是把自己的信息注册到哪个NameServer上去的？ 每个Broker启动都得向所有的NameServer进行注册 比如一共有10台Broker机器，2个NameServer机器，然后其中5台Broker会把自己的信息注册到1个NameServer上去，另外5台Broker会把自己的信息注册到另外1个NameServer上去。这样搞有一个最大的问题，如果1台NameServer上有5个Broker的信息，另外1个NameServer上有另外5个Broker的信息，那么此时 任何一个NameServer宕机了，不就导致5个Broker的信息就没了吗 扮演生产者和消费者的系统们，如何从NameServer那儿获取到集群的Broker信息呢？知道集群里有哪些Broker，根据一定的算法挑选一个Broker去发送消息或者获取消息第一种办法是这样，NameServer那儿会主动发送请求给所有的系统，告诉他们Broker信息。 NameServer无法知道要推送Broker信息给哪些系统第二种办法是这样的，每个系统自己每隔一段时间，定时发送请求到NameServer去拉取最新的集群Broker信息。 RocketMQ中的生产者和消费者就是这样，自己主动去NameServer拉取Broker信息 如果Broker挂了，NameServer是怎么感知到的？ Broker跟NameServer之间的心跳机制，Broker会每隔30s给所有的NameServer发送心跳，告诉每个NameServer自己目前还活着。 NameServer会每隔10s运行一个任务，去检查一下各个Broker的最近一次心跳时间，如果某个Broker超过120s都没发送心跳了，则认为这个Broker挂掉了 Broker挂了，系统是怎么感知到的？ 可能某个系统就会发送消息到那个已经挂掉的Broker上去，此时是绝对不可能成功发送消息的 可以考虑不发送消息到那台Broker，改成发到其他Broker上去。 你必须要发送消息给那台Broker，Slave机器是一个备份，可以继续使用，可以考虑Slave进行通信 系统又会重新从NameServer拉取最新的路由信息了，此时就会知道有一个Broker已经宕机了。 RocketMQ Broker原理分析 Master Broker是如何将消息同步给Slave Broker的？ Master Broker主动推送给Slave Broker？还是Slave Broker发送请求到Master Broker去拉取？ RocketMQ的Master-Slave模式采取的是Slave Broker不停的发送请求到Master Broker去拉取消息 RocketMQ自身的Master-Slave模式采取的是Pull模式拉取消息 RocketMQ 实现读写分离了吗？ Master Broker主要是接收系统的消息写入，然后会同步给Slave Broker 作为消费者的系统在获取消息的时候，是从Master Broker获取的？还是从Slave Broker获取的？ 有可能从Master Broker获取消息，也有可能从Slave Broker获取消息 Master Broker在返回消息给消费者系统的时候，会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系 统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。 举个例子，Master Broker负载很重, 所以此时Master Broker就会建议你从Slave Broker去拉取消息。 举另外一个例子，本身这个时候Master Broker上都已经写入了100万条数据了，结果Slave Broke同步的特别慢， 才同步了96万条数据，落后了整整4万条消息的同步，这个时候你作为消费者系统可能都获取到96万条数据了，那么下次还是只能从Master Broker去拉取消息。 如果Slave Broke挂掉了有什么影响？ 有一点影响，但是影响不太大 消息写入全部是发送到Master Broker的，消息获取也可以走Master Broker，只不过有一些消息获取可能是从Slave Broker 去走的。所以如果Slave Broker挂了，那么此时无论消息写入还是消息拉取，还是可以继续从Master Broke去走，对整体运行不影响。 只不过少了Slave Broker，会导致所有读写压力都集中在Master Broker上。 如果Master Broker挂掉了该怎么办？ 对消息的写入和获取都有一定的影响了。但是其实本质上而言，Slave Broker也是跟Master Broker一样有一份数据在的， 只不过Slave Broker上的数据可能有部分没来得及从Master Broker同步。 此时RocketMQ可以实现直接自动将Slave Broker切换为Master Broker吗？不能 Master-Slave模式不是彻底的高可用模式，他没法实现自动把Slave切换为Master 基于Dledger实现RocketMQ高可用自动切换RocketMQ 4.5之后，RocketMQ支持了一种基于Raft协议实现的一个机制，叫做Dledger,,Dledger融入RocketMQ之后，可以让一个Master Broker对应多个Slave Broker，也就是说一份数据可以有多份副本，比如一个Master Broker对应两个Slave Broker。此时一旦Master Broker宕机了，就可以在多个副本，也就是多个Slave中，通过Dledger技术和Raft协议算法进行leader选举，直接将一个Slave Broker选举为新的Master Broker，然后这个新的Master Broker就可以对外提供服务了。整个过程也许只要10秒或者几十秒的时间就可以完成，这样的话，就可以实现Master Broker挂掉之后，自动从多个Slave Broker中选举出来一个新的Master Broker，继续对外服务，一切都是自动的。 高可用部署方案 NameServer集群化部署，保证高可用，建议3台机器 基于Dledger的Broker主从架构 Dledger技术是要求至少得是一个Master带两个Slave，这样有三个Broke组成一个Group，也就是作为一个分组来运行。一旦 Master宕机，他就可以从剩余的两个Slave中选举出来一个新的Master对外提供服务 Broker是如何跟NameServer进行通信的? Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去，30s心跳一次，120秒检查一次是否一直没有心跳包 使用MQ的系统都要多机器集群部署 生产者 消费者 MQ的核心数据模型:Topic到底是什么? Topic不能直译，表达的意思就是一个数据集合的意思，不同类型的数据你得放不同的Topic Topic作为一个数据集合是怎么在Broker集群里存储的? 分布式存储 多个master 创建Topic的时候指定数据分散存储在多台Broker机器 生产者系统是如何将消息发送给Broker的? 在发送消息之前，得先有一个Topic，然后在发送消息的时候你得指定你要发送到哪个Topic里面去。 生产者跟nameserver建立长连接，拉取路由信息找到要投递消息的Topic分布在哪几台Broker上，根据负载均衡算法，从里面选择一台Broke机器出来 选择一台Broker，跟这个Broker建立一个TCP长连接，通过长连接向Broker发送消息 消费者是如何从Broker上拉取消息的? 消费者跟nameserver建立长连接，拉取路由信息,接着找到自己要获取消息的 Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息 rocket mq可视化界面管理工具 git clone https://github.com/apache/rocketmq-externals.git 进入rocketmq-console的目录 cd rocketmq-externals/rocketmq-console 执行以下命令对rocketmq-cosole进行打包，把他做成一个jar包: mvn package -DskipTests 进入target目录下，可以看到一个jar包，接着执行下面的命令启动工作台: java -jar rocketmq-console-ng-1.0.1.jar –server.port=8080 –rocketmq.config.namesrvAddr=127.0.0.1:9876 中间件系统，对os内核参数调整vm.overcommit_memory 有三个值可以选择，0、1、2 0，在中间件系统申请内存的时候，os内核会检查可用内存是否足够，如果足够的话就分配内存给你，如果感觉剩余内存不是太够了，干脆就拒绝你的申请，导致你申请内存失败，进而导致中间件系统异常出错。 1，把所有可用的物理内存都允许分配给你，只要有内存就给你来用，可以避免申请内存失败的问题。因此一般需要将这个参数的值调整为1比如我们曾经线上环境部署的Redis就因为这个参数是0，导致在save数据快照到磁盘文件的时候，需要申请大内存的时候被拒绝了，进而导致了异常报错。用如下命令修改:echo ‘vm.overcommit_memory=1’ &gt;&gt; /etc/sysctl.conf。 vm.max_map_count 默认值是65536 会影响中间件系统可以开启的线程的数量 默认值有时候是不够的，比如我们大数据团队的生产环境部署的Kafka集群曾经有一次就报出过这个异常，说无法开启足够多的线程，直接导致Kafka宕机了。建议可以把这个参数调大10倍，比如655360这样的值，保证中间件可以开启足够多的线程。用如下命令修改:echo ‘vm.max_map_count=655360’ &gt;&gt; /etc/sysctl.conf。 vm.swappiness用来控制进程的swap行为，os会把一部分磁盘空间作为swap区域，有的进程现在可能不是太活跃，就会被操作系统把进程调整为睡眠状态，把进程中的数据放入磁盘上的swap区域，然后让这个进程把原来占用的内存空间腾出来，交给其他活跃运行的进程来使用。 如果这个参数的值设置为0，意思就是尽量别把任何一个进程放到磁盘swap区域去，尽量大家都用物理内存。 如果这个参数的值是100，那么意思就是尽量把一些进程给放到磁盘swap区域去，内存腾出来给活跃的进程使用。 默认这个参数的值是60，有点偏高了，可能会导致我们的中间件运行不活跃的时候被迫腾出内存空间然后放磁盘swap区域去。 生产环境建议把这个参数调整小一些，比如设置为10，尽量用物理内存，别放磁盘swap区域去。用如下命令修改:echo ‘vm.swappiness=10’ &gt;&gt; /etc/sysctl.conf。 ulimit用来控制linux上的最大文件链接数的，默认值可能是1024，一般肯定是不够的，因为你在大量频繁的读写磁盘文件的时候，或者是进行网络通信的时候，都会跟这个参数有关系 对于一个中间件系统而言肯定是不能使用默认值的，如果你采用默认值，很可能在线上会出现如下错误:error: too many open files。因此通常建议用如下命令修改这个值:echo ‘ulimit -n 1000000’ &gt;&gt; /etc/profile。 中间件系统，对jvm参数调整 -server:服务器模式启动 -Xms8g -Xmx8g -Xmn4g:默认的堆大小是8g内存，新生代是4g内存 -XX:+UseG1GC -XX:G1HeapRegionSize=16m:用了G1垃圾回收器来做分代回收，对新生代和老年代都是用G1来回收，G1的region大小设置为了16m，这个因-为机器内存比较多，所以region大小可以调大一些给到16m，不然用2m的region，会导致致region数量过多的 -XX:G1ReservePercent=25:G1管理的老年代里预留25%的空闲内存，保证新生代对象晋升到老年代的时候有足够空间，避免老年代内存都满了，新生代有对象要进入老年代没有充足内存了，默认值是10%，偏少，调大 -XX:InitiatingHeapOccupancyPercent=30:当堆内存的使用率达到30%之后就会自动启动G1的并发垃圾回收，开始尝试回收一些垃圾对象默认值是45%，调低，提高了GC的频率，避免了垃圾对象过多，一次垃圾回收耗时过长的问题 -XX:SoftRefLRUPolicyMSPerMB=0:建议这个参数不要设置为0，避免频繁回收一些软引用的Class对象，调整为比如1000 -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps - XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation - XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m:控制GC日志打印输出的，gc日志文件的地址，打印哪些详细信息，每个gc日志文件的大小是30m，最多保留5个gc日志文件。 -XX:-OmitStackTraceInFastThrow:有时候JVM会抛弃一些异常堆栈信息，这个参数设置之后，禁用这个特性，要把完整的异常堆栈信息打印出来 -XX:+AlwaysPreTouch:刚开始指定JVM用多少内存，不会真正分配给他，会在实际需要使用的时候再分配给他，使用这个参数之后，就是强制让JVM启动的时候直接分配我们指定的内存，不要等到使用内存的时候再分配 -XX:MaxDirectMemorySize=15g:RocketMQ里大量用了NIO中的direct buffer，限定了direct buffer最多申请多少， 如果你机器内存比较大，可以适当调大这个值 -XX:-UseLargePages -XX:-UseBiasedLocking:这两个参数的意思是禁用大内存页和偏向锁RocketMQ默认的JVM参数是采用了G1垃圾回收器，默认堆内存大小是8G 可以根据机器内存来调整，增大一些也是没有问题的，然后就是一些G1的垃圾回收的行为参数做了调整，对RocketMQ核心参数进行调整sendMessageThreadPoolNums=16 RocketMQ内部用来发送消息的线程池的线程数量，默认是16 根据你的机器的CPU核数进行适当增加，比如机器CPU是24核的，可以增加这个线程数量到24或者30 压测在RocketMQ的TPS和机器的资源使用率和负载之间取得一个平衡。例如：两个Producer不停的往RocketMQ集群发送消息，每个Producer所在机器启动了80个线程，相当于每台机器有80个线程并发的往RocketMQ集群写入消息。RocketMQ集群是1主2从组成的一个dledger模式的高可用集群，只有一个Master Broker会接收消息的写入，有2个Cosumer不停的从RocketMQ集群消费数据。每条数据的大小是500个字节。 cpu负载情况 top 内存使用率 free JVM GC频率 gc日志 磁盘IO负载 top 网卡流量 服务器使用的是千兆网卡，千兆网卡的理论上限是每秒传输128M数据，但是一般实际最大值是每秒传输100M数据 sar -n DEV 1 2 RocketMQ处理到每秒7万消息的时候，每条消息500字节左右的大小的情况下，每秒网卡传输数据量已经达到100M了，就是已经达到了网卡的一个极限值 订单系统改造 发消息的几种方式（生产者） 同步发送消息到MQ 通过代码发送消息到MQ去，SendResult sendResult = producer.send(msg)，然后等待mq返回一个结果继续往下执行 异步发送消息到MQ 消息发送出去，不会等待MQ返回结果，当MQ返回结果给你的时候，Producer会回调你的SendCallback里的函数，发送成功回调onSuccess函数，发送失败了回调onExceptino函数。 发送单向消息到RocketMQ 发送一个消息给MQ，不会等待mq返回结果，不会关注MQ有没有返回结果，不管发送的消息是成功还是失败 收消息的几种方式（消费者） push模式 Broker会主动把消息发送给消费者，消费者是被动的接收Broker推送给过来的消息，然后进行处理 pull模式 消费者主动发送请求到Broker去拉取消息并处理 对其他团队要获取你们核心数据的问题，应该如何解决? 定时同步 统计数据按天，周可以定时同步 实时同步 发mq，其他团队消费，容许延迟 调接口 告知 其他团队拉数据 提供接口给他们 秒杀场景下？高并发读,抢购商品界面 cdn + nginx + redis 提前将商品数据放入redis, 使用nginx + lua 本地缓存和redis缓存加载商品页面高并发写 独立于订单系统，新建秒杀订单系统，避免秒杀时影响普通订单的下订单 客户端页面需要新增答题功能，防止作弊 nginx + lua 判断库存为0拦截下单接口，避免更多的请求直接打到下单接口 调用下单接口，商品库存存redis,扣减库存 下单接口 采用将数据写入mq，从而避免瞬间高并发数据库，使数据库宕机,订单系统拉取mq数据进行下单 Topic、MessageQueue和Broker之间的关系是什么? 在创建Topic的时候需要指定一个很关键的参数，就是MessageQueue,指定你的这个Topic对应了多少个队列，也就是多少个MessageQueue 每个MessageQueue中会平均分配Topic的数据,每个Broker机器上都存储一些MessageQueue，MessageQueue是RocketMQ中非常关键的一个数据分片机制，通过这个方法，就可以实现Topic数据的分布式存储! 生产者会跟NameServer进行通信获取Topic的路由数据，生产者从NameServer中就知道一个Topic有几个MessageQueue，哪些MessageQueue在哪台Broker机器上，基于写入MessageQueue的策略，从而使消息分散在多个broker上 Master Broker挂了，此时正在等待的其他Slave Broker自动热切换为Master Broker，那么这个时候对这一组Broker就没有Master Broker可以写入了按照之前的策略来均匀把数据写入各个Broker上的MessageQueue，那么会导致你在一段时间内，每次访问到这个挂掉的 Master Broker都会访问失败，在Producer中开启一个开关，sendLatencyFaultEnable 一个自动容错机制，某次访问一个Broker发现网络延迟有500ms，无法访问，自动回避访问这个Broker一段时间 broker如何存数据？ commitlog 顺序写文件 当生产者的消息发送到一个Broker上的时候，broker接收到了一条消息，将这个消息直接写入磁盘上的一个日志文件，叫做CommitLog，直接顺序写入这个文件，CommitLog是很多磁盘文件，每个文件限定最多1GB，Broker收到消息之后就直接追加写入这个文件的末尾，如果一个CommitLog写满了1GB，就会创建一个新的CommitLog文件。 MessageQueue在数据存储中是体现在哪里呢? 在Broker中，对Topic下的每个MessageQueue都会有一系列的ConsumeQueue文件。 在Broker的磁盘上，这种格式的一系列文件: $HOME/store/consumequeue/{topic}/{queueId}/{fileName} {topic}指代的就是某个Topic，{queueId}指代的就是某个MessageQueue，有很多的ConsumeQueue文件，ConsumeQueue文件里存储的是一条消息对应在CommitLog文件中的offset偏移量，还包含了消息的长度，以及tag hashcode，一条数据是20个字节 如何让消息写入CommitLog文件近乎内存写性能的? Broker是基于OS操作系统的PageCache和顺序写两个机制 数据写入CommitLog文件的时候，不是直接写入底层的物理磁盘文件，先写入OS的PageCache内存缓存中，然后由OS的后台线程选一个时间，异步化的将OS PageCache内存缓冲中的数据刷入底层的磁盘文件。 磁盘文件顺序写+OS PageCache写入+OS异步刷盘的策略，基本上可以让消息写入CommitLog的性能 跟你直接写入内存里是差不多的 异步刷盘模式，消息写入吞吐量非常高，可能会有数据丢失的风险 （Broker将消息写入OS PageCache中，就直接返回ACK，尚未刷入磁盘，宕机丢数据） 同步刷盘模式 必须强制把消息刷入底层的物理磁盘文件中，然后才会返回ack给producer 基于Dledger的高可用broker如何运行？ 基于DLedger技术管理CommitLog 用DLedger先替换掉原来Broker 自己管理的CommitLog，由DLedger来管理CommitLog Broker基于DLedger管理的CommitLog 去构建出来机器上的各个ConsumeQueue磁盘文件 Broker集群启动时，基于DLedger技术和Raft协议完成Leader选举 每个节点都投票给自己 选举失败后，每个节点随机休眠，先醒的机器投票给自己并发送投票信息给其他节点，其他节点醒了收到先醒机器的投票，会投票给先醒的节点 选票 大于等于（机器数/2+1）,选为master节点 Leader Broker写入之后，基于DLedger技术和Raft协议同步给Follower Broker 数据同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段 首先Leader Broker上的DLedger收到一条数据之后，会标记为uncommitted状态，通过自己的DLedgerServer组件把这个uncommitted数据发送给Follower Broker的DLedgerServer。Follower Broker的DLedgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的DLedgerServer，然后如果Leader Broker收到超过半数的Follower Broker返回ack之后，就会将消息标记为committed状态。Leader Broker上的DLedgerServer就会发送commited消息给Follower Broker机器的DLedgerServer，让他们也把消息标记为 comitted状态。 如果Leader Broker崩溃，则基于DLedger和Raft协议重新选举Leader 基于DLedger还是采用Raft协议的算法，去选举出来一个新的Leader Broker继续对外提供服务，而且会对没有完成的数据同步进行一些恢复性的操作，保证数据不会丢失。 消费者是如何获取消息并处理？ 消费者组概念 一组消费者的简称，集群模式下，一个消费组获取到一条消息，只会交给组内的一台机器去处理，广播模式下，消费组获取到的一条消息，组内每台机器都可以获取到这条消息 重温MessageQueue、CommitLog、ConsumeQueue之间的关系 MessageQueue会分散在多个Broker上，在每个Broker机器上，一 个MessageQueue就对应了一个ConsumeQueue，在物理磁盘上其实是对应了多个ConsumeQueue文件的， MessageQueue与消费者的关系 均匀的将MessageQueue分配给消费组的多台机器来消费 Push模式 vs Pull模式 两个消费模式本质都是消费者机器主动发送请求到Broker机器去拉取一批消息下来。 Push是Broker会尽可能实时的把新消息交给消费者机器来进行处理，消息时效性会更好。 一般我们使用RocketMQ的时候，消费模式通常都是基于他的Push模式来做的，因为Pull模式的代码写起来更加的复杂和繁琐 Push当消费者发送请求到Broker去拉取消息，有新的消息可以消费那么就会立马返回一批消息到消费机器去处理，处理完之后会接着立刻发送请求到Broker机器去拉取下一批消息。 Push模式下有一个请求挂起和长轮询的机制 当消费者的请求发送到Broker，没有新的消息给你处理的时候，就会让请求线程挂起，默认是挂起15秒，后台线程每隔一会儿检查一下是否有的新的消息，在这个挂起过程中，有新的消息到达了会主动唤醒挂起的线程，然后把消息返回给消费者。 Broker是如何将消息读取出来返回给消费机器的? 要消费的MessageQueue以及开始消费的位置，去找到对应的ConsumeQueue读取里面对应位置的消息在CommitLog中的物理offset偏移量，然后到CommitLog中根 消费者机器如何处理消息、进行ACK以及提交消费进度? 处理完这批消息之后，消费者机器就会提交我们目前的一个消费进度到Broker上去，然后Broker就会存储我们的消费进度 如果消费组中出现机器宕机或者扩容加机器，会怎么处理? 如果消费组中出现机器宕机或者扩容加机器的情况，他会怎么处理?这个时候其实会进入一个rabalance的环节，也就是说重新给各个消费机器分配他们要处理的MessageQueue。 消费者根据什么策略从master还是slave拉取消息？ ConsumeQueue文件也是基于os cache的 os读取一个磁盘文件时，自动把磁盘文件里的数据缓存到os cache中 ConsumeQueue文件主要是存放消息的offset，文件小，30万条消息的offset就只有5.72MB。实际上ConsumeQueue文件是不占用多少磁盘空间的，整体数据量很小，几乎可以完全被os缓存在内存cache里。 根据你读取到的offset去CommitLog里读取消息的完整数据 os cache对于CommitLog而言，主要是提升文件写入性能，当你不停的写入的时候，很多最新写入的数据都会先停留在os cache里，比如这可能有10GB~20GB的数据。os会自动把cache里的比较旧的一些数据刷入磁盘里，腾出来空间给更新写入的数据放在os cache里 如果你读取的是那种刚刚写入CommitLog的数据，大概率停留在os cache中，可以直接从os cache里读取CommitLog中的数据，这个就是内存读取，性能是很高的。 读取的是比较早之前写入CommitLog的数据，数据被刷入磁盘，不存在os cache里了，只能从磁盘上的文件里读取，性能是比较差 Master Broker什么时候会让你从Slave Broker拉取数据? 对比你当前没有拉取消息的数量和大小，以及最多可以存放在os cache内存里的消息的大小，如果没拉取的消息超过了最大能使用的内存的量，那么说明你后续会频繁从磁盘加载数据，此时就让你从slave broker去加载数据了 基于mmap技术实现磁盘高性能读写 传统文件读写： 普通的IO操作的一个弊端，必然涉及到两次数据拷贝操作，对磁盘读写性能是有影响的。 - 从磁盘上把数据读取到内核IO缓冲区里，再从内核IO缓存区里读取到用户进程私有空间，才能拿到这个文件里的数据 - 必须先把数据写入到用户进程私有空间里去，再进入内核IO缓冲区，最后进入磁盘文件里去。 mmap技术 建立用户进程私有空间的虚拟内存和文件物理磁盘地址映射，此时并没有任何的数据拷贝操作，JDK NIO包下的MappedByteBuffer的map()函数 将文件映射到内存。mmap技术在进行文件映射的时候，一般有大小限制，在1.5GB~2GB之间 mmap + page cache 接下来MappedByteBuffer执行写入操作，写入的时候直接进入PageCache中，过一段时间之后，由os的线程异步刷入磁盘中 判断要读取的数据是否在PageCache里?如果在的话，直接从PageCache里读取。如果不在PageCache，会从磁盘文件里加载数据到PageCache中，PageCache技术在加载数据的时候，会将你加载的数据块的临近的其他数据块一起加载到PageCache中。 丢数据场景 生产者往broker发送数据，网络异常没有发送成功 broker正常接受到数据，写入page cache ，异步刷盘策略，未刷盘机器宕机 leader故障，slave切换leader过程中，这个过程出现异常 磁盘坏了 消费者读取消息策略自动提交offset，数据未处理完宕机 解决丢数据 RocketMQ的事务消息机制确定生产者发送的消息到达broker 首先要让生产者去发送一条half消息到MQ去，这个half消息本质就是一个业务执行成功的消息，可以理解这个消息的状态是half状态，这时消费者系统是看不见这个half消息的，生产者等待接收half消息写入成功的响应通知 half消息给MQ失败了，报错了，可能mq挂了，可能网络故障了，这时执行回滚操作 half消息成功，生产者系统完成自己的任务 生产者系统做自己的任务时发生异常，需要发rollback给mq,让mq删除half消息 生产者系统完成自己的任务，需要commit half消息，发一个commit请求给mq rocketmq 有一个补偿，扫描自己的half消息，如果一直没有commit或rollback 会回调生产者系统的接口，询问这个消息是commit还是rollback 异步刷盘改为同步刷盘 调整broker的配置文件，将其中的flushDiskType配置设置为:SYNC_FLUSH，默认他的值是ASYNC_FLUSH，即默认是异步刷盘的。 消费端 改为不自动提交offset RocketMQ的消费者中会注册一个监听器，MessageListenerConcurrently，当你的消费者获取到一批消息之后，回调你的这个监听器函数，让消费者系统处理这一批消息。 默认的Consumer的消费模式，处理完一批消息了，才会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS状态标识消息都处理结束，去提交offset到broker去 事务机制底层实现原理 half消息写入到rocketmq内部的“RMQ_SYS_TRANS_HALF_TOPIC”这个Topic对应的一个ConsumeQueue里，此时就会认为half消息写入成功，响应给生产者系统 定时任务会去扫描RMQ_SYS_TRANS_HALF_TOPIC中的half消息，超过一定时间还是half消息，回调生产者的接口，让系统判断这个half消息是要rollback还是commit 执行rollback操作，RocketMQ就会在OP_TOPIC里写入一条记录，标记half消息已经是rollback状态 执行commit操作之后，RocketMQ就会在OP_TOPIC里写入一条记录，标记half消息已经是commit状态，接着需要把放在RMQ_SYS_TRANS_HALF_TOPIC中的half消息给写入到业务topic的ConsumeQueue里去，然后消费者系统可以看见 一直没有执行commit/rollback，RocketMQ会回调订单系统的接口去判断half消息的状态，最多就是回调15次，如果15次之后没法告知他half消息的状态，自动把消息标记为rollback。 同步发送+反复重试发送的缺陷 反复重试耗时，影响接口返回 反复重试失败，回滚业务代码不方便，本地事务容易会滚，但是操作中间件的不容易会滚 反复重试失败，未会滚业务代码，导致系统之间数据不一致，未收到消息的系统与发送消息的系统数据不一致 消息重复消费原因？ 生产者接口由于意外原因被调用多次 反复重试代码有概率重复发送 消费者消费未提交offset之前系统重启 幂等性，保证数据不会重复消费 生产者保证幂等性 利用rocket mq 可查询已发送消息判断 利用redis 存储已发过的消息，存在缺陷，消息已推送mq，未写入redis，系统重启 RocketMQ支持你查询某个消息是否存在的，性能也不是太好，会影响接口的性能。基于Redis的消息发送状态的方案，在极端情况下还是没法100%保证幂等性 消费者保证幂等性 推荐业务判断法，直接根据你的数据存储中的记录来判断这个消息是否处理过， 如果处理过，那就别再次处理 消息消费过程异常怎么办？ 重试流程？ RocketMQ会有一个针对你这个ConsumerGroup的重试队列，如果消费消息返回RECONSUME_LATER状态，就会把这个消息放到这个消费者组的重试队列中，消费组的名称是“VoucherConsumerGroup”，一个消费者组，那么会有一个 “%RETRY%VoucherConsumerGroup”的重试队列 过一段时间，重试队列中的消息会再次给消费者处理，如果再次失败，又返回了RECONSUME_LATER，那么会再过一段时间让我们来进行处理，默认最多是重试16次! 重试时间间隔 messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 重试失败了怎么办？ 重试了16次还一直没处理成功，就不要继续重试这批消息，同时消息会自动进入死信队列。 死信队列的名字是“%DLQ%VoucherConsumerGroup” 可以开一个后台线程，订阅“%DLQ%VoucherConsumerGroup”死信队列， 对死信队列中的消息，一直不停的处理 消息过滤发送消息时，给消息设置tag或者属性 12Message msg = new Message(&quot;topic&quot;,&quot;tag&quot;,data.getBytes()); 指定tagmsg.putUserProperty(&quot;props&quot;,10);添加属性 消费数据的时候根据tag和属性进行过滤 123consumer.subscribe(&quot;topic&quot;,&quot;tag1||tag2&quot;);或consumer.subscribe(&quot;topic&quot;,MessageSelector.bySql(&quot;props &gt; 10s&quot;)) RocketMQ还是支持比较丰富的数据过滤语法的，如下所示:(1)数值比较，比如: &gt;，&gt;=，&lt;，&lt;=，BETWEEN，=;(2)字符比较，比如: =，&lt;&gt;，IN;(3)IS NULL 或者 IS NOT NULL;(4)逻辑符号 AND，OR，NOT;(5)数值，比如:123，3.1415;(6)字符，比如:’abc’，必须用单引号包裹起来;(7)NULL，特殊的常量(8)布尔值，TRUE 或 FALSE 延迟消息12Message msg = new Message(&quot;topic&quot;,&quot;tag&quot;,data.getBytes()); 指定tagmsg.setDelayTimeLevel(3);添加延迟级别 发送延迟消息的核心，就是设置消息的delayTimeLevel延迟级别RocketMQ默认支持延迟级别:1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h代码中设置延迟级别为3，意思就是延迟10s，发送出去的消息，会过10s被消费者获取到。 基于消息key来定位消息是否丢失可以基于消息key来实现，通过如下方式设置一个消息的key为订单id:message.setKeys(orderId)接着这个消息到broker上，会基于key构建hash索引，这个hash索引就存放在IndexFile索引文件里。通过MQ提供的命令去根据key查询这个消息:mqadmin queryMsgByKey -n 127.0.0.1:9876 - t SCANRECORD -k orderId 权限控制Broker的配置文件里需要设置aclEnable=true这个配置，开启权限控制Broker部署机器的${ROCKETMQ_HOME}/store/config目录下，可以放一个plain_acl.yml的配置文件 1234567891011121314151617181920212223242526272829# 这个参数就是全局性的白名单# 这里定义的ip地址，都是可以访问Topic的globalWhiteRemoteAddresses:- 13.21.33.*- 192.168.0.*# 这个accounts就是说，你在这里可以定义很多账号# 每个账号都可以在这里配置对哪些Topic具有一些操作权限accounts:# 这个accessKey其实就是用户名的意思，比如我们这里叫做“订单技术团队” - accessKey: OrderTeam# 这个secretKey其实就是这个用户名的密码secretKey: 123456# 下面这个是当前这个用户名下哪些机器要加入白名单的whiteRemoteAddress:# admin指的是这个账号是不是管理员账号admin: false# 这个指的是默认情况下这个账号的Topic权限和ConsumerGroup权限defaultGroupPerm: SUB# 这个就是这个账号具体的堆一些账号的权限# 下面就是说当前这个账号对两个Topic，都具备PUB|SUB权限，就是发布和订阅的权限 # PUB就是发布消息的权限，SUB就是订阅消息的权限# DENY就是拒绝你这个账号访问这个TopictopicPerms:- CreateOrderInformTopic=PUB|SUB - PaySuccessInformTopic=PUB|SUB# 下面就是对ConsumerGroup的权限，也是同理的 groupPerms:- groupA=DENY- groupB=PUB|SUB- groupC=SUB# 下面就是另外一个账号了，比如是商品技术团队的账号 - accessKey: ProductTeamsecretKey: 12345678 whiteRemoteAddress: 192.168.1.*# 如果admin设置为true，就是具备一切权限 admin: true 消息消费链路 broker的配置文件里开启traceTopicEnable=true开启消息轨迹追踪。 当启动这个Broker的时候会自动创建出来一个内部的Topic，RMQ_SYS_TRACE_TOPIC，用来存储所有的消息轨迹追踪的数据的。 1DefaultMQProducer producer = new DefaultMQProducer(&quot;topic&quot;,true); //第二个参数enableMsgTrace= true表示对消息开启轨迹追踪 RocketMQ控制台里，在导航栏里就有一个消息轨迹，在里面可以创建查询任务， 根据messageId、message key或者Topic来查询，Producer、Broker、Consumer上报的一些轨迹数据 Broker记录消息的轨迹数据，包括如下:消息存储的Topic、消息存储的位置、消息的key、消息的 tags。 Consumer端上报信息， 包括：Consumer的信息、投递消息的时间、这是第几轮投递消息、消息消费是否成功、消费这条消息的耗时 消息积压了怎么办？4台机器20个message queue 消息积压了 临时申请16台机器多部署16个消费者系统的实例，然后20个消费者系统同时消费，每个人消费一个MessageQueue的 消息 消费者系统底层依赖的数据库必须要能抗住临时增加了5倍的读写压力 mq故障了怎么办？ 异常重试、失败存储、恢复发送 针对这种场景，生产者系统中设计高可用的降级方案，发送消息到MQ代码里去try catch捕获异常，有异常进行重试。 连续重试了超过n次还是失败，说明MQ集群可能彻底崩溃，这时消息写入到本地存储（数据库、本地磁盘文件、NoSQL存储） 不停的尝试发送消息到MQ去，一旦发现MQ集群恢复，有一个后台线程可以把之前持久化存储的消息都查询出来，依次按照顺序发送到MQ集群里","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.imder.top/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.imder.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"mysql优化","slug":"mysql优化","date":"2022-02-28T14:59:29.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2022/02/28/mysql优化/","link":"","permalink":"https://blog.imder.top/2022/02/28/mysql%E4%BC%98%E5%8C%96/","excerpt":"","text":"mysql优化聚集索引和非聚集索引 聚集索引一个表只能有一个，而非聚集索引一个表可以存在多个 聚集索引存储记录是物理上连续存在，而非聚集索引是逻辑上的连续，物理存储并不连续 聚集索引:物理存储按照索引排序；聚集索引是一种索引组织形式，索引的键值逻辑顺序决定了表数据行的物理存储顺序。非聚集索引:物理存储不按照索引排序；非聚集索引则就是普通索引，仅仅只是对数据列创建相应的索引，不影响整个表的物理存储顺序。 聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。 mysql的myisam和innodb区别 索引结构 InnoDB的数据文件本身就是主索引文件 MyISAM的主索引和数据是分开的 InnoDB的辅助索引data域存储相应记录主键的值而不是地址 MyISAM的辅助索引和主索引没有多大区别 InnoDB是聚簇索引，数据挂在主键索引之下 锁 myisam 只支持表锁 innodb 支持行锁 事务 myisam 没有事务和mvcc innodb 支持事务和mvcc 主键 MyISAM允许没有任何索引和主键的表存在，索引都是保存行的地址 InnoDB如果没有设定主键或非空唯一索引，就会自动生成一个6字节的主键，数据是主索引的一部分，附加索引保存的是主索引的值 外键 MyISAM不支持，InnoDB支持 b-tree和b+tree一棵m阶的B-Tree有如下特性： 1. 每个节点最多有m个孩子。 2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。 3. 若根节点不是叶子节点，则至少有2个孩子 4. 所有叶子节点都在同一层，且不包含其它关键字信息 5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn） 6. 关键字的个数n满足：ceil(m/2)-1 &lt;= n &lt;= m-1 7. ki(i=1,…n)为关键字，且关键字升序排序。 8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1) 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。 模拟查找关键字29的过程： 1. 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】 2. 比较关键字29在区间（17,35），找到磁盘块1的指针P2。 3. 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】 4. 比较关键字29在区间（26,30），找到磁盘块3的指针P2。 5. 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】 6. 在磁盘块8中的关键字列表中找到关键字29。 B+Tree是在B-Tree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。B+Tree相对于B-Tree有几点不同： 1. 非叶子节点只存储键值信息。 2. 所有叶子节点之间都有一个链指针。 3. 数据记录都存放在叶子节点中。“”推算： InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为〖10〗^3）。 也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * （16KB/每条数据的大小+键值=100B）= 1600万 条记录。 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2-4层。 mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。 执行计划explain两个变种 explain extended:会在 explain 的基础上额外提供一些查询优化的信息，紧随其后通过 show warnings 命令可以得到优化后的查询语句，从而看出优化器优化了什么。 例如：explain extended select * from film where id = 1; sshow warnings; explain partitions:相比 explain 多了个 partitions 字段，如果查询是基于分区表的 话，会显示查询将访问的分区。 explain中的列 id列 select语句的编号，越大越先执行 相同编号，从上往下执行 select_type列 simple 简单查询 primary 复杂查询最外层的查询 subquery 子查询但是不包括from后的子查询 derived from 后的子查询 union union后的select table列 查询的表 当from子句中有子查询时，table列是 格式，表示当前查询依赖 id=N 的查 询，于是先执行 id=N 的查询 当有 union 时，UNION RESULT 的 table 列的值为&lt;union1,2&gt;，1和2表示参与 union 的 select 行id type列：查询类型 system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL 一般来说，得保证查询达到range级别，最好达到ref const, system:mysql能对查询的某部分进行优化并将其转化成一个常量 eq_ref:primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。 ref: 简单 select 查询，name是普通索引(非唯一索引)；关联表查询，使用联合索引连接 range：范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;= 等操作中。使用一个索引来检索给定范围的行。 index:扫描全表索引 ALL:全表扫描， possible_keys列 可能使用哪些索引来查找 key列 mysql实际采用哪个索引来优化对该表的访问 key_len列 mysql在索引里使用的字节数，算出具体使用了索引中的哪些列。 key_len计算规则如下: 字符串:char(n):n字节长度;varchar(n):2字节存储字符串长度，如果是utf-8，则长度 3n +2。数值类型:tinyint:1字节;smallint:2字节;int:4字节 ;bigint:8字节。时间类型:date:3字节;timestamp:4字节;datetime:8字节 如果字段允许为 NULL，需要1字节记录是否为 NULL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 ref列 key列记录的索引中，表查找值所用到的列或常量，常见的有:const(常量)，字段名 rows列 mysql估计要读取并检测的行数，注意不是结果集里的行数。 Extra列:额外信息 1)Using index:查询的列被索引覆盖，并且where筛选条件是索引的是前导列 2)Using where:查询的列未被索引覆盖，where筛选条件非索引的前导列 3)Using index condition:查询的列不全在索引中，where条件中是一个前导列的范围；查询列不完全被索引覆盖，查询条件完全可以使用到索引 4)Using temporary:mysql需要创建一张临时表来处理查询 5)Using filesort:将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序 6)Select tables optimized away:使用某些聚合函数(比如 max、min)来访问存在索引的某个字段 Using where Using index 查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的不是前导列 NULL 查询的列未被索引覆盖，并且where筛选条件是索引的前导列，需要回表 调优索引实践 查询条件全值匹配 最左前缀法则，联合索引，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 不在索引列上做任何操作(计算、函数、(自动or手动)类型转换)，会导致索引失效而转向全表扫描 存储引擎不能使用联合索引（A，B）中（A）范围条件右边的列（B） 尽量使用覆盖索引(只访问索引的查询(索引列包含查询列))，减少select *语句 mysql在使用不等于(!=或者&lt;&gt;)的时候无法使用索引会导致全表扫描 is null,is not null 也无法使用索引 like以通配符开头(‘%abc…’)mysql索引失效会变成全表扫描操作 解决like’%字符串%’索引不被使用的方法? a)使用覆盖索引，查询字段必须是建立覆盖索引字段 b)如果不能使用覆盖索引则可能需要借助搜索引擎 字符串不加单引号索引失效 少用or或in，用它查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、 表大小等多个因素整体评估是否使用索引，详见范围查询优化 范围查询优化，可能是由于单次数据量查询过大导致优化器最终选择不走索引 优化方法:可以讲大的范围拆分成多个小 为什么推荐建表时字段为not null? 通常情况下最好指定列为NOT NULL，除非真的需要存储NULL值。 如果查询中包含可为NULL的列，对MySql来说更难优化，因为可为NULL的列使得索引、索引统计和值比较都更复杂。 可为NULL的列会使用更多的存储空间，在MySql里也需要特殊处理。当可为NULL的列被索引时，每个索引记录需要一个额外的字节，在MyISAM里甚至还可能导致固定大小的索引（例如只有一个整数列的索引）变成可变大小的索引。 通常把可为NULL的列改为NOT NULL带来的性能提升比较小，所以（调优时）没有必要首先在现有schema中查找并修改掉这种情况，除非确定这会导致问题。 如果计划在列上建索引，就应该尽量避免设计成可为NULL的列。 mysql的默认值 对于MySql而言，如果不主动设置为NOT NULL的话，那么插入数据的时候默认值就是NULL。NULL和NOT NULL使用的空值代表的含义是不一样，NULL可以认为这一列的值是未知的，空值则可以认为我们知道这个值，只不过他是空的而已。举个例子，一张表中的某一条name字段是NULL，我们可以认为不知道名字是什么，反之如果是空字符串则可以认为我们知道没有名字，他就是一个空值。而对于大多数程序的情况而言，没有什么特殊需要非要字段要NULL的吧，NULL值反而会对程序造成比如空指针的问题。 默认值为NULL带来的问题 聚合函数不准确 对于NULL值的列，使用聚合函数的时候会忽略NULL值。例如：有一张表，name字段默认是NULL，此时对name进行count得出的结果是1，这个是错误的。count(*)是对表中的行数进行统计，count(name)则是对表中非NULL的列进行统计。 =失效 对于NULL值的列，是不能使用=表达式进行判断的，下面对name的查询是不成立的，必须使用is NULL。 与其他值运算 NULL和其他任何值进行运算都是NULL，包括表达式的值也是NULL。user表第二条记录age是NULL，所以+1之后还是NULL，name是NULL，进行concat运算之后结果还是NULL。 distinct、group by、order by 对于distinct和group by来说，所有的NULL值都会被视为相等，对于order by来说升序NULL会排在最前。 索引问题 官方文档：使用is NULL和范围查询都是可以和正常一样使用索引的，只不过在某些场景下，由于mysql的执行策略导致索引失效。 sql执行过程中，到优化器阶段，会选择使用什么索引比较合理，sql具体执行方案在这里确定下来，索引列存在NULL就会导致优化器在做索引选择的时候更复杂，更加难以优化。 排序优化 MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 order by满足两种情况会使用Using index。 order by语句使用索引最左前列。 使用where子句与order by子句条件列组合满足索引最左前列。 尽量在索引列上完成排序，遵循索引建立(索引创建的顺序)时的最左前缀法则。 如果order by的条件不在索引列上，就会产生Using filesort。 能用覆盖索引尽量用覆盖索引 group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对于group by的优化如果不需要排序的可以加上order by null禁止排序。注意，where高于having，能写在where中 的限定条件就不要去having限定了。 Using filesort文件排序原理详解 filesort文件排序方式 单路排序:是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序;用trace工具可 以看到sort_mode信息里显示&lt; sort_key, additional_fields &gt;或者&lt; sort_key, packed_additional_fields &gt; 双路排序(回表排序模式):是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段;用trace工具 可以看到sort_mode信息里显示&lt; sort_key, rowid &gt; MySQL 通过比较系统变量 max_length_for_sort_data(默认1024字节) 的大小和需要查询的字段总大小来 判断使用哪种排序模式。如果 max_length_for_sort_data 比查询字段的总长度大，那么使用 单路排序模式; 如果 max_length_for_sort_data 比查询字段的总长度小，那么使用 双路排序模式。 例如：select * from a_table where b = ‘111’ order by c; 注：字段b建立索引，字段c无索引 单路排序: 索引b找到第一个满足 b = ‘111’ 条件的主键id 根据主键 id 取出整行，取出所有字段的值，存入 sort_buffer 中 从索引b找到下一个满足 b = ‘111’ 条件的主键 id 重复步骤 2、3 直到不满足 b = ‘111’ 对 sort_buffer 中的数据按照字段 c 进行排序 返回结果给客户端 双路排序: set max_length_for_sort_data = 10; ‐‐设置表所有字段长度总和肯定大于10字节 从索引 b 找到第一个满足 b = ‘111’ 的主键id 根据主键 id 取出整行，把排序字段 c 和主键 id 这两个字段放到 sort buffer 中 从索引 b 取下一个满足 b = ‘111’ 记录的主键 id 重复 3、4 直到不满足 b = ‘111’ 对 sort_buffer 中的字段 c 和主键 id 按照字段 c 进行排序 遍历排序好的 id 和字段 c，按照 id 的值回到原表中取出 所有字段的值返回给客户端 如果全部使用sort_buffer内存排序一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增 大sort_buffer(默认1M)，mysql很多参数设置都是做过优化的，不要轻易调整。 分页查询优化例如：select * from employees limit 10000,10从表 employees 中取出从 10001 行开始的 10 行记录。看似只查询了 10 条记录，实际这条 SQL 是先读取 10010 条记录，然后抛弃前 10000 条记录，然后读到后面 10 条想要的数据。因此要查询一张大表比较靠后的数据，执行效率 是非常低的。 按照主键排序并limit：条件：主键自增且连续，结果是按照主键排序的 select * from employees where id &gt; 90000 limit 5; 没单独加 order by，表示通过主键排序 根据非主键字段排序的分页查询:连接子查询，子查询使用覆盖索引 select * from employees ORDER BY name limit 90000,5; name字段有索引，但是查询计划显示没有走索引，使用索引比全表扫描成本高 优化方案：select * from employees e inner join (select id from employees order by name limit 90000,5) eq on eq.id = e.id join关联优化 mysql的表关联常见有两种算法 Nested-Loop Join 算法 Block Nested-Loop Join 算法 嵌套循环连接 Nested-Loop Join(NLJ)算法 ：优化器一般会优先选择小表做驱动表，执行计划 Extra 中未出现 Using join buff 循环地从第一张表(称为驱动表)中读取行，在这行数据中取到关联字段，根据关联字段在另一张表(被驱动表)里取出满足条件的行，然后取出两张表的结果合集。 select*from t1 inner join t2 on t1.a= t2.a; 这里假设t2小表（100条） t1大表 （10000） 上面sql的大致流程如下: 从表 t2 中读取一行数据; 从第 1 步的数据中，取出关联字段 a，到表 t1 中查找; 取出表 t1 中满足条件的行，跟 t2 中获取到的结果合并，作为结果返回给客户端; 重复上面 3 步。 整个过程会读取 t2 表的所有数据(扫描100行)，然后遍历这每行数据中字段 a 的值，根据 t2 表中 a 的值索引扫描 t1 表 中的对应行(扫描100次 t1 表的索引，1次扫描可以认为最终只扫描 t1 表一行完整数据，也就是总共 t1 表也扫描了100 行)。因此整个过程扫描了 200 行。 如果被驱动表的关联字段没索引，使用NLJ算法性能会比较低(下面有详细解释)，mysql会选择Block Nested-Loop Join 算法。 基于块的嵌套循环连接 Block Nested-Loop Join(BNL)算法：被驱动表连接字段无索引 把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比。 select*from t1 inner join t2 on t1.b= t2.b; 这里假设t2小表（100条） t1大表 （10000） 把 t2 的所有数据放入到 join_buffer 中 把表 t1 中每一行取出来，跟 join_buffer 中的数据做对比 3. 返回满足 join 条件的数据 整个过程对表 t1 和 t2 都做了一次全表扫描，因此扫描的总行数为10000(表 t1 的数据总量) + 100(表 t2 的数据总量) = 10100。并且 join_buffer 里的数据是无序的，因此对表 t1 中的每一行，都要做 100 次判断，所以内存中的判断次数是 100 * 10000= 100 万次。 被驱动表的关联字段没索引为什么要选择使用 BNL 算法而不使用 Nested-Loop Join 呢?如果上面第二条sql使用 Nested-Loop Join，那么扫描行数为 100 * 10000 = 100万次，这个是磁盘扫描。很显然，用BNL磁盘扫描次数少很多，相比于磁盘扫描，BNL的内存计算会快得多。 in和exsits优化 ：小表驱动大表 A表与B表的ID字段应建立索引 in:当B表的数据集小于A表的数据集时，in优于exists12345select * from A where id in(select id from B)等价于 for bid in select * from B select * from A where id = bid //先扫描索引，然后在根据索引查数据 exists:当A表的数据集小于B表的数据集时，exists优于in12345select * from A where exists(select 1 from B where B.id=A.id) 等价于 for(select * from A)&#123; select * from B where B.id = A.id&#125; count（*）优化id为主键，name普通索引EXPLAIN select count(1) from employees;EXPLAIN select count(id) from employees;EXPLAIN select count(name) from employees;EXPLAIN select count(*) from employees;四个sql的执行计划一样，说明这四个sql执行效率应该差不多，区别在于根据某个字段count不会统计字段为null值的数据行为什么mysql最终选择辅助索引而不是主键聚集索引?因为二级索引相对主键索引存储数据更少，检索性能应该更高 常见优化方法1、查询mysql自己维护的总行数 对于myisam存储引擎的表做不带where条件的count查询性能是很高的，因为myisam存储引擎的表的总行数会被 mysql存储在磁盘上，查询不需要计算对于innodb存储引擎的表mysql不会存储表的总记录行数，查询count需要实时计算2、show table status 如果只需要知道表总行数的估计值可以用如下sql查询，性能很高3、将总数维护到Redis里 插入或删除表数据行的时候同时维护redis里的表总行数key的计数值(用incr或decr命令)，但是这种方式可能不准，很难 保证表操作和redis操作的事务一致性4、增加计数表 插入或删除表数据行的时候同时维护计数表，让他们在同一个事务里操作 锁 锁分类 性能上分为乐观锁和悲观锁 对数据库的操作上分为读锁(共享锁：多个读不影响)和写锁(排他锁：阻断其他读写锁)，都属于悲观锁 从数据的操作粒度上分表锁和行锁 表锁 每次操作锁住整张表。开销小，加锁快;不会出现死锁;锁定粒度大，发生锁冲突的概率最高，并发度最低 手动增加表锁 lock table 表名称 read(write),表名称2 read(write); 查看表上加过的锁show open tables; 删除表锁 unlock tables; MyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。 读锁会阻塞写，不会阻塞读。写锁则会把读和写都阻塞 行锁 每次操作锁住一行数据。开销大，加锁慢;会出现死锁;锁定粒度最小，发生锁，冲突的概率最低，并发度最高。 InnoDB与MYISAM的最大不同有两点: 支持事务(TRANSACTION) 支持行级锁 面试过程中如何回答mysql相关的优化？ 从建表语句 主键尽量使用整形自增 占用空间小 主键自增，新增的数据永远在后面 排序效率高 范围查找 表字段使用not null,null值很难查询且占用额外空间 单表字段不要太多 建立查询字段索引 从一条查询语句 不用select* 尽可能使用覆盖索引，避免回表 join 字段建立索引 大表 in 小表 ，小表 exist 大表 查询条件不用函数 避免使用不等于 对于连续数值，使用BETWEEN不用IN 避免like ‘%xxx’ 不做列运算 limit 查询用连接子查询优化，子查询使用覆盖索引 拆分大的delete或insert语句 可通过开启慢查询日志来找出较慢的SQL","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://blog.imder.top/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://blog.imder.top/tags/Mysql/"}]},{"title":"逻辑关系划分","slug":"逻辑关系划分","date":"2022-02-22T22:22:22.000Z","updated":"2024-03-28T16:43:20.083Z","comments":true,"path":"2022/02/22/逻辑关系划分/","link":"","permalink":"https://blog.imder.top/2022/02/22/%E9%80%BB%E8%BE%91%E5%85%B3%E7%B3%BB%E5%88%92%E5%88%86/","excerpt":"","text":"逻辑关系划分带”除非”的句子一共有3种情况 除非和否则一起使用， 除非A，否则B，等同于 非A-&gt;B【范例】除非你去，否则我不去。用逻辑表述为： 你不去-&gt;我不去 “除非”单独出现，没有其他逻辑连词，默认省略了“否则”。比如说：（否则）B，除非A，等同于，除非A，否则B【范例】他这次死定了，除非出现奇迹。等于除非出现奇迹，否则他死定了逻辑表述：非死定-&gt;出现奇迹，不出现奇迹-&gt;死定了 带有逻辑连词”除非”的句子，还有其他的逻辑连词“若”“如果”“才”类似于“除非。。。才”，“如果…，除非…”，在带有其他逻辑连词的句子里，在这些句子里”除非”就是“必须的意思”除非A，才B，等同于必须A，才B，逻辑表述为 A&lt;-B 如果（若）A，除非B，等同于如果A，必须B，逻辑表述为 A-&gt;B 【第一家】把若A，除非B，理解为除非A,否则不B，就等同于非A-&gt;非B，逆否后还是B-&gt;A。除非天上掉馅饼，否则不嫁给你，非天上掉馅饼==》不嫁给你 【第二家】若A，除非B，理解为如果A，那么B，逻辑表示还是A==》B，所以这三种理解从逻辑的本质来说，最终是相同的。【范例】如果我嫁给你了，除非天上掉馅饼（1）除非替换为必须我嫁给你，必须天上掉馅饼，等同于，天上不掉馅饼==》不嫁给你（2）“如果”，理解为“否则不”除非天上掉馅饼，否则不嫁给你，等同于，非天上掉馅饼=》不嫁给你（3）理解为，如果，那么,如果嫁给你，那么天上掉馅饼，等同于，嫁给你==》掉馅饼，逆否后：不掉馅饼==》不嫁给你这三种理解，最中得出的逻辑本质是完全相同的。","categories":[{"name":"逻辑","slug":"逻辑","permalink":"https://blog.imder.top/categories/%E9%80%BB%E8%BE%91/"}],"tags":[{"name":"逻辑","slug":"逻辑","permalink":"https://blog.imder.top/tags/%E9%80%BB%E8%BE%91/"}]},{"title":"sentinel","slug":"springcloudsentinel","date":"2022-02-22T14:20:47.000Z","updated":"2024-03-28T16:43:20.067Z","comments":true,"path":"2022/02/22/springcloudsentinel/","link":"","permalink":"https://blog.imder.top/2022/02/22/springcloudsentinel/","excerpt":"","text":"sentinel添加依赖 在pom文件中dependencyManagement里添加依赖1234567 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2021.1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 在pom文件中dependencies里添加依赖1234 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; 抛出异常的方式定义资源 定义流控规则123456789public static void initRule()&#123; FlowRule flowRule = new FlowRule(); flowRule.setResource(&quot;helloworld&quot;); flowRule.setCount(2); flowRule.setGrade(RuleConstant.FLOW_GRADE_QPS); ArrayList arrayList = new ArrayList(); arrayList.add(flowRule); FlowRuleManager.loadRules(arrayList);&#125; 判断是否限流1234567891011121314 public static void helloworld()&#123; try&#123; Entry helloworld = SphU.entry(&quot;helloworld&quot;); System.out.println(&quot;通过&quot;); &#125;catch (Exception e)&#123; System.out.println(&quot;限流&quot;); &#125;finally &#123; // SphU.entry(xxx) 需要与 entry.exit() 成对出现,否则会导致调用链记录异常 if (entry != null) &#123; entry.exit(); &#125; &#125;&#125; 限流实现方式二: 注解方式定义资源 @SentinelResource(value = “资源名称”,blockHandler =”handleFlowQpsException” ,fallback =”queryOrderInfo2Fallback”) blockHandler = “handleFlowQpsException”用来处理Sentinel 限流/熔断等错误； fallback = “queryOrderInfo2Fallback”用来处理接口中业务代码所有异常(如业务代码异常、sentinel限流熔断异常等) 在接口OrderQueryService中，使用注解实现订单查询接口的限流： 123456789101112131415161718192021222324252627282930313233@SentinelResource(value = &quot;getOrderInfo&quot;, blockHandler = &quot;handleFlowQpsException&quot;, fallback = &quot;queryOrderInfo2Fallback&quot;)public String queryOrderInfo2(String orderId) &#123; // 模拟接口运行时抛出代码异常 if (&quot;000&quot;.equals(orderId)) &#123; throw new RuntimeException(); &#125; System.out.println(&quot;获取订单信息:&quot; + orderId); return &quot;return OrderInfo :&quot; + orderId;&#125;/** * 订单查询接口抛出限流或降级时的处理逻辑 * * 注意: 方法参数、返回值要与原函数保持一致 * @return */public String handleFlowQpsException(String orderId, BlockException e) &#123; e.printStackTrace(); return &quot;handleFlowQpsException for queryOrderInfo2: &quot; + orderId;&#125;/** * 订单查询接口运行时抛出的异常提供fallback处理 * * 注意: 方法参数、返回值要与原函数保持一致 * @return */public String queryOrderInfo2Fallback(String orderId, Throwable e) &#123; return &quot;fallback queryOrderInfo2: &quot; + orderId;&#125; 控制台的使用启动Sentinel控制台 下载地址：https://github.com/alibaba/Sentinel/releases 启动命令：java -Dserver.port=8080 \\ Dcsp.sentinel.dashboard.server=localhost:8080 \\ jar target/sentinel-dashboard.jar 客户端接入（Spring Boot项目接入控制台 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt; &lt;version&gt;$&#123;sentinel.version&#125;&lt;/version&gt;&lt;/dependency&gt; 配置 JVM 启动参数： 1-Dproject.name=sentinel-demo -Dcsp.sentinel.dashboard.server=127.0.0.1:8080 -Dcsp.sentinel.api.port=8719 控制台页面","categories":[{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/categories/Springcloud/"}],"tags":[{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/tags/Springcloud/"}]},{"title":"Springcloud-config","slug":"springcloudconfig","date":"2022-02-22T11:59:29.000Z","updated":"2024-03-28T16:43:20.067Z","comments":true,"path":"2022/02/22/springcloudconfig/","link":"","permalink":"https://blog.imder.top/2022/02/22/springcloudconfig/","excerpt":"","text":"configConfig server添加依赖12345678&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; Application.properties配置12345678910spring.cloud.config.server.git.uri=https://gitee.com/rzxbest/springcloud-config.gitspring.cloud.config.server.git.username=********spring.cloud.config.server.git.password=********spring.cloud.config.server.git.search-paths=configspring.cloud.config.server.default-label=mastereureka.instance.hostname=localhosteureka.client.registerWithEureka=trueeureka.client.fetchRegistry=trueeureka.client.serviceUrl.defaultZone:http://$&#123;eureka.instance.hostname&#125;:8761/eureka/ 访问配置文件访问配置信息的URL与配置文件的映射关系如下所示： /{ application } / {profile} [/{label}] /{ application }-{profile}. yml /{ label }/{ application }-{profile}.yml /{ application }-{profile}.properties /{ label }/{ application }-{profile}.properties上面的 url 会映射 {application}-{profile} .properties 对应的配置文件，其中 {label} 对应Git上不同的分支，默认为 master 。我们可以尝试构造不同的 url 来访问不同的配置内容， 例如：http://localhost:8888/{applicationName}/{profile}/{label} , label分支，不传的话默认master。 Config client添加依赖12345678&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置 bootstrap.propertiesserver.port=8769 123456789spring.application.name=CLOUD-CONFIG-CLIENTeureka.instance.hostname=localhosteureka.client.registerWithEureka=trueeureka.client.fetchRegistry=trueeureka.client.serviceUrl.defaultZone:http://$&#123;eureka.instance.hostname&#125;:8761/eureka/spring.cloud.config.profile=devspring.cloud.config.name=client-appspring.cloud.config.discovery.serviceId=CLOUD-CONFIG-SERVERspring.cloud.config.discovery.enabled=true 配置刷新手动调用config-client的refresh接口 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt;&lt;/dependency&gt; 添加配置 12management.endpoints.web.exposure.include=refreshmanagement.endpoints.web.discovery.enabled=true 需用使用配置的类加@RefreshScope Post请求接口 自动刷新,利用git webhook 安装rabbitmq configserver添加依赖12345678910&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;version&gt;2.6.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; configserver添加配置123456spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guestmanagement.endpoints.web.exposure.include=* Configclient 添加依赖 12345678910 &lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;version&gt;2.6.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; ConfigClient 添加配置1234spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 需要刷新的配置类加@RefreshScope 配置configserver bus-refresh webhookhttp://localhost:8768/actuator/bus-refresh","categories":[{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/categories/Springcloud/"}],"tags":[{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/tags/Springcloud/"}]},{"title":"Springcloud-gateway","slug":"springgateway","date":"2022-02-22T10:59:29.000Z","updated":"2024-03-28T16:43:20.075Z","comments":true,"path":"2022/02/22/springgateway/","link":"","permalink":"https://blog.imder.top/2022/02/22/springgateway/","excerpt":"","text":"gateway文档地址 https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.1.0.RELEASE/multi/multi_spring-cloud-gateway.html Springcloud通用配置 Eureka server 配置 12345server.port=8761eureka.instance.hostname=localhosteureka.client.registerWithEureka=falseeureka.client.fetchRegistry=falseeureka.client.serviceUrl.defaultZone:http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 服务配置 123456server.port=8760spring.application.name=CLOUD-SERVICEeureka.instance.hostname=localhosteureka.client.registerWithEureka=trueeureka.client.fetchRegistry=trueeureka.client.serviceUrl.defaultZone:http://$&#123;eureka.instance.hostname&#125;:8761/eureka/ 网关配置 123456server.port=8088spring.application.name=CLOUD-GATEWAYeureka.instance.hostname=localhosteureka.client.registerWithEureka=trueeureka.client.fetchRegistry=trueeureka.client.serviceUrl.defaultZone:http://$&#123;eureka.instance.hostname&#125;:8761/eureka/ 以服务名为前缀访问服务接口 在网关配置加入1spring.cloud.gateway.discovery.locator.enabled=true predicates断言路由 在网关配置中加入以下配置123spring.cloud.gateway.routes[0].id= 1spring.cloud.gateway.routes[0].uri=http://localhost:8760spring.cloud.gateway.routes[0].predicates[0]=Path=/demo/** 过滤器 加入以下配置123spring.cloud.gateway.routes[0].filters[0].name=AddRequestParameterspring.cloud.gateway.routes[0].filters[0].args[name]=tokenspring.cloud.gateway.routes[0].filters[0].args[value]=abcdef 过滤器对结果进行处理 对结果进行处理 官方文档提供的 modifyResponseBody过滤器 添加Java配置 123456789101112131415161718@Beanpublic RouteLocator routes(RouteLocatorBuilder builder,ObjectMapper mapper) &#123;return builder.routes().route(&quot;id2&quot;, r -&gt; r.path(&quot;/modify/**&quot;).filters(gatewayFilterSpec-&gt; &#123;gatewayFilterSpec.modifyResponseBody(String.class,String.class,(exchange,s) -&gt;&#123;String result = s;try&#123;Map map = mapper.readValue(s, Map.class);map.put(&quot;add&quot;,&quot;this is modify&quot;);result = mapper.writeValueAsString(map);&#125;catch (Exception e)&#123;&#125;return Mono.just(result); &#125;);return gatewayFilterSpec;&#125;).uri(URI.create(&quot;http://localhost:8760&quot;))).build();&#125; 结果 全局过滤器自定义全局过滤器12345678910111213@Bean@Order(-1)public GlobalFilter a() &#123; return (exchange, chain) -&gt; &#123; if (exchange.getRequest().getQueryParams().containsKey(&quot;token&quot;))&#123; return chain.filter(exchange).doOnSuccess(s-&gt;&#123; exchange.getResponse().getHeaders().add(&quot;token&quot;,exchange.getRequest().getQueryParams().get(&quot;token&quot;).get(0)); &#125;); &#125;else&#123; return chain.filter(exchange); &#125; &#125;;&#125; 或者实现GlobalFilter、 Order接口 接入actuator添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置12management.endpoint.gateway.enabled=truemanagement.endpoints.web.exposure.include=gateway 访问地址 /actuator/gateway/globalfilters /actuator/gateway/routefilters /actuator/gateway/refresh /actuator/gateway/routes /actuator/gateway/routes/{id} POST request to /gateway/routes/{id_route_to_create} DELETE request to /gateway/routes/{id_route_to_delete}. 自定义Filter 实现GatewayFilterFactory 或者继承AbstractGatewayFilterFactory12345678910111213141516171819202122public class AddResponseHeaderGatewayFilterFactory extends AbstractNameValueGatewayFilterFactory &#123;@Overridepublic GatewayFilter apply(NameValueConfig config) &#123;return new GatewayFilter() &#123;@Overridepublic Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;String value = ServerWebExchangeUtils.expand(exchange, config.getValue());exchange.getResponse().getHeaders().add(config.getName(), value); return chain.filter(exchange); &#125; @Override public String toString() &#123; return filterToStringCreator(AddResponseHeaderGatewayFilterFactory.this) .append(config.getName(), config.getValue()).toString(); &#125; &#125;;&#125;&#125;","categories":[{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/categories/Springcloud/"}],"tags":[{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/tags/Springcloud/"}]},{"title":"ExceptionHandler和ControllerAdvice注解分析","slug":"@ControllerAdvice与@ModelAttribute、@InitBinder注解混合使用","date":"2022-02-21T19:59:29.000Z","updated":"2024-03-28T16:43:20.059Z","comments":true,"path":"2022/02/21/@ControllerAdvice与@ModelAttribute、@InitBinder注解混合使用/","link":"","permalink":"https://blog.imder.top/2022/02/21/@ControllerAdvice%E4%B8%8E@ModelAttribute%E3%80%81@InitBinder%E6%B3%A8%E8%A7%A3%E6%B7%B7%E5%90%88%E4%BD%BF%E7%94%A8/","excerpt":"","text":"@ControllerAdvice与@ModelAttribute、@InitBinder注解混合使用@ModelAttribute注解的作用 用在方法的参数上 注解在参数上，会将客户端传递过来的参数按名称注入到指定对象中， 并且会将这个对象自动加入ModelMap中 用在Controller的方法上 注解在方法上，会在每一个@RequestMapping标注的方法前执行， 如果有返回值，则自动将该返回值加入到ModelMap中 @InitBinder注解混合使用 对数据绑定进行设置 WebDataBinder中有很多方法可以对数据绑定进行具体的设置1234@InitBinderpublic void initBinder(WebDataBinder binder) &#123; binder.setDisallowedFields(&quot;name&quot;);&#125; 注册已有封装好的编辑器 由于前台传到controller里的值是String类型的，当往Model里Set这个值的时候，如果set的这个属性是个对象，Spring就会去找到对应的editor进行转换，然后再set进去 Spring自己提供了大量的实现类（如下图所示的在org.springframwork.beans.propertyEditors下的所有editor），诸如CustomDateEditor ，CustomBooleanEditor，CustomNumberEditor等许多，基本上够用 如何加载 RequestMappingHandlerAdapter？自己注入或者使用默认的 12345678910111213141516171819202122232425262728293031323334private void initHandlerAdapters(ApplicationContext context) &#123; this.handlerAdapters = null; if (this.detectAllHandlerAdapters) &#123; //true // Find all HandlerAdapters in the ApplicationContext, including ancestor contexts. Map&lt;String, HandlerAdapter&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerAdapter.class, true, false);//从容器中获取HandlerAdapter.class if (!matchingBeans.isEmpty()) &#123; this.handlerAdapters = new ArrayList&lt;&gt;(matchingBeans.values()); // We keep HandlerAdapters in sorted order. AnnotationAwareOrderComparator.sort(this.handlerAdapters); &#125; &#125; else &#123; try &#123; HandlerAdapter ha = context.getBean(HANDLER_ADAPTER_BEAN_NAME, HandlerAdapter.class); this.handlerAdapters = Collections.singletonList(ha); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, we&#x27;ll add a default HandlerAdapter later. &#125; &#125; // Ensure we have at least some HandlerAdapters, by registering // default HandlerAdapters if no other adapters are found. if (this.handlerAdapters == null) &#123; this.handlerAdapters = getDefaultStrategies(context, HandlerAdapter.class);//从DispatchServlet.properties中获取 if (logger.isTraceEnabled()) &#123; logger.trace(&quot;No HandlerAdapters declared for servlet &#x27;&quot; + getServletName() + &quot;&#x27;: using default strategies from DispatcherServlet.properties&quot;); &#125; &#125;&#125; DispatchServlet.properties中获取HandlerAdapter1234org.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter,\\ org.springframework.web.servlet.function.support.HandlerFunctionAdapter 何时加载@ControllerAdvice与@ModelAttribute、@InitBinder注解？RequestMappingHandlerAdapter类实现了InitializingBean接口，在afterPropertiesSet方法中initControllerAdviceCache方法中加载 123456789101112131415161718192021222324252627282930313233343536373839public static final MethodFilter INIT_BINDER_METHODS = method -&gt; AnnotatedElementUtils.hasAnnotation(method, InitBinder.class);public static final MethodFilter MODEL_ATTRIBUTE_METHODS = method -&gt; (!AnnotatedElementUtils.hasAnnotation(method, RequestMapping.class) &amp;&amp; AnnotatedElementUtils.hasAnnotation(method, ModelAttribute.class));private void initControllerAdviceCache() &#123; if (getApplicationContext() == null) &#123; return; &#125; //从容器中获取ControllerAdvice注解的bean List&lt;ControllerAdviceBean&gt; adviceBeans = ControllerAdviceBean.findAnnotatedBeans(getApplicationContext()); List&lt;Object&gt; requestResponseBodyAdviceBeans = new ArrayList&lt;&gt;(); //遍历每个bean,找出InitBinder注解的方法放入initBinderAdviceCache里，找出ModelAttribute注解的方法放入modelAttributeAdviceCache for (ControllerAdviceBean adviceBean : adviceBeans) &#123; Class&lt;?&gt; beanType = adviceBean.getBeanType(); if (beanType == null) &#123; throw new IllegalStateException(&quot;Unresolvable type for ControllerAdviceBean: &quot; + adviceBean); &#125; Set&lt;Method&gt; attrMethods = MethodIntrospector.selectMethods(beanType, MODEL_ATTRIBUTE_METHODS); if (!attrMethods.isEmpty()) &#123; this.modelAttributeAdviceCache.put(adviceBean, attrMethods); &#125; Set&lt;Method&gt; binderMethods = MethodIntrospector.selectMethods(beanType, INIT_BINDER_METHODS); if (!binderMethods.isEmpty()) &#123; this.initBinderAdviceCache.put(adviceBean, binderMethods); &#125; if (RequestBodyAdvice.class.isAssignableFrom(beanType) || ResponseBodyAdvice.class.isAssignableFrom(beanType)) &#123; requestResponseBodyAdviceBeans.add(adviceBean); &#125; &#125; ...省略&#125; 何时调用 @ModelAttribute、@InitBinder注解的方法或参数？ 在RequestMappingHandlerAdapter对象调用handle方法中调用 handle方法调用handleInternal方法,handleInternal方法调用invokeHandlerMethod方法 invokeHandlerMethod 方法中getDataBinderFactory方法获取InitBinder注解的方法 invokeHandlerMethod 方法中getModelFactory方法获取ModelAttribute注解的方法 调用ModelFactory对象的initModel方法，initModel方法中调用invokeModelAttributeMethods方法，调用@ModelAttribute注解的方法 调用ModelFactory对象的initModel方法，initModel方法中调用findSessionAttributeArguments方法，对@ModelAttribute注解的参数赋值 invocableMethod.invokeAndHandle(webRequest, mavContainer)，在这个方法中调用invokeForRequest(),invokeForRequest()中调用getMethodArgumentValues()方法对参数进行了绑定 getDataBinderFactory方法 getModelFactory方法 先从controller类获取@InitBinder注解的方法 在从@ControllerAdvice注解的bean上获取@InitBinder注解的方法 上述的方法组合并返回ModelFactory 1234567891011121314151617181920212223private WebDataBinderFactory getDataBinderFactory(HandlerMethod handlerMethod) throws Exception &#123; Class&lt;?&gt; handlerType = handlerMethod.getBeanType(); Set&lt;Method&gt; methods = this.initBinderCache.get(handlerType); if (methods == null) &#123; methods = MethodIntrospector.selectMethods(handlerType, INIT_BINDER_METHODS); this.initBinderCache.put(handlerType, methods); &#125; List&lt;InvocableHandlerMethod&gt; initBinderMethods = new ArrayList&lt;&gt;(); // Global methods first this.initBinderAdviceCache.forEach((controllerAdviceBean, methodSet) -&gt; &#123; if (controllerAdviceBean.isApplicableToBeanType(handlerType)) &#123; Object bean = controllerAdviceBean.resolveBean(); for (Method method : methodSet) &#123; initBinderMethods.add(createInitBinderMethod(bean, method)); &#125; &#125; &#125;); for (Method method : methods) &#123; Object bean = handlerMethod.getBean(); initBinderMethods.add(createInitBinderMethod(bean, method)); &#125; return createDataBinderFactory(initBinderMethods);&#125; 先从controller类获取@ModelAttribute注解的方法 在从@ControllerAdvice注解的bean上获取@ModelAttribute注解的方法 上述的方法组合并返回ModelFactory12345678910111213141516171819202122232425private ModelFactory getModelFactory(HandlerMethod handlerMethod, WebDataBinderFactory binderFactory) &#123; SessionAttributesHandler sessionAttrHandler = getSessionAttributesHandler(handlerMethod); Class&lt;?&gt; handlerType = handlerMethod.getBeanType(); Set&lt;Method&gt; methods = this.modelAttributeCache.get(handlerType); if (methods == null) &#123; methods = MethodIntrospector.selectMethods(handlerType, MODEL_ATTRIBUTE_METHODS); this.modelAttributeCache.put(handlerType, methods); &#125; List&lt;InvocableHandlerMethod&gt; attrMethods = new ArrayList&lt;&gt;(); // Global methods first this.modelAttributeAdviceCache.forEach((controllerAdviceBean, methodSet) -&gt; &#123; if (controllerAdviceBean.isApplicableToBeanType(handlerType)) &#123; Object bean = controllerAdviceBean.resolveBean(); for (Method method : methodSet) &#123; attrMethods.add(createModelAttributeMethod(binderFactory, bean, method)); &#125; &#125; &#125;); for (Method method : methods) &#123; Object bean = handlerMethod.getBean(); attrMethods.add(createModelAttributeMethod(binderFactory, bean, method)); &#125; return new ModelFactory(attrMethods, binderFactory, sessionAttrHandler);&#125; invokeModelAttributeMethods方法1234567891011121314151617181920212223242526272829303132333435private void invokeModelAttributeMethods(NativeWebRequest request, ModelAndViewContainer container) throws Exception &#123; while (!this.modelMethods.isEmpty()) &#123; InvocableHandlerMethod modelMethod = getNextModelMethod(container).getHandlerMethod(); ModelAttribute ann = modelMethod.getMethodAnnotation(ModelAttribute.class); Assert.state(ann != null, &quot;No ModelAttribute annotation&quot;); if (container.containsAttribute(ann.name())) &#123; if (!ann.binding()) &#123; container.setBindingDisabled(ann.name()); &#125; continue; &#125; Object returnValue = modelMethod.invokeForRequest(request, container); if (modelMethod.isVoid()) &#123; if (StringUtils.hasText(ann.value())) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Name in @ModelAttribute is ignored because method returns void: &quot; + modelMethod.getShortLogMessage()); &#125; &#125; continue; &#125; String returnValueName = getNameForReturnValue(returnValue, modelMethod.getReturnType()); if (!ann.binding()) &#123; container.setBindingDisabled(returnValueName); &#125; if (!container.containsAttribute(returnValueName)) &#123; container.addAttribute(returnValueName, returnValue); &#125; &#125;&#125; findSessionAttributeArguments方法12345678910111213private List&lt;String&gt; findSessionAttributeArguments(HandlerMethod handlerMethod) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); for (MethodParameter parameter : handlerMethod.getMethodParameters()) &#123; if (parameter.hasParameterAnnotation(ModelAttribute.class)) &#123; String name = getNameForParameter(parameter); Class&lt;?&gt; paramType = parameter.getParameterType(); if (this.sessionAttributesHandler.isHandlerSessionAttribute(name, paramType)) &#123; result.add(name); &#125; &#125; &#125; return result;&#125; getMethodArgumentValues方法12345678910111213141516171819202122232425262728293031323334353637protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; MethodParameter[] parameters = getMethodParameters(); if (ObjectUtils.isEmpty(parameters)) &#123; return EMPTY_ARGS; &#125; Object[] args = new Object[parameters.length]; for (int i = 0; i &lt; parameters.length; i++) &#123; MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); args[i] = findProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; if (!this.resolvers.supportsParameter(parameter)) &#123; throw new IllegalStateException(formatArgumentError(parameter, &quot;No suitable resolver&quot;)); &#125; try &#123; args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); &#125; catch (Exception ex) &#123; // Leave stack trace for later, exception may actually be resolved and handled... if (logger.isDebugEnabled()) &#123; String exMsg = ex.getMessage(); if (exMsg != null &amp;&amp; !exMsg.contains(parameter.getExecutable().toGenericString())) &#123; logger.debug(formatArgumentError(parameter, exMsg)); &#125; &#125; throw ex; &#125; &#125; return args;&#125;","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/categories/JAVA/"},{"name":"Spring","slug":"JAVA/Spring","permalink":"https://blog.imder.top/categories/JAVA/Spring/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/tags/Spring/"}]},{"title":"ExceptionHandler和ControllerAdvice注解分析","slug":"ExceptionHandler和ControllerAdvice注解分析","date":"2022-02-21T18:59:29.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2022/02/21/ExceptionHandler和ControllerAdvice注解分析/","link":"","permalink":"https://blog.imder.top/2022/02/21/ExceptionHandler%E5%92%8CControllerAdvice%E6%B3%A8%E8%A7%A3%E5%88%86%E6%9E%90/","excerpt":"","text":"ExceptionHandler和ControllerAdvice注解分析DispatcherServlet如何加载HandlerExceptionResolver？12345678910111213141516171819202122232425262728293031323334private void initHandlerExceptionResolvers(ApplicationContext context) &#123; this.handlerExceptionResolvers = null; if (this.detectAllHandlerExceptionResolvers) &#123; //默认为true // Find all HandlerExceptionResolvers in the ApplicationContext, including ancestor contexts. Map&lt;String, HandlerExceptionResolver&gt; matchingBeans = BeanFactoryUtils .beansOfTypeIncludingAncestors(context, HandlerExceptionResolver.class, true, false); if (!matchingBeans.isEmpty()) &#123; this.handlerExceptionResolvers = new ArrayList&lt;&gt;(matchingBeans.values()); // We keep HandlerExceptionResolvers in sorted order. AnnotationAwareOrderComparator.sort(this.handlerExceptionResolvers); &#125; &#125; else &#123; try &#123; HandlerExceptionResolver her = context.getBean(HANDLER_EXCEPTION_RESOLVER_BEAN_NAME, HandlerExceptionResolver.class); this.handlerExceptionResolvers = Collections.singletonList(her); &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Ignore, no HandlerExceptionResolver is fine too. &#125; &#125; // Ensure we have at least some HandlerExceptionResolvers, by registering // default HandlerExceptionResolvers if no other resolvers are found. if (this.handlerExceptionResolvers == null) &#123; this.handlerExceptionResolvers = getDefaultStrategies(context, HandlerExceptionResolver.class); //从默认的DispatcherServlet.properties取 if (logger.isTraceEnabled()) &#123; logger.trace(&quot;No HandlerExceptionResolvers declared in servlet &#x27;&quot; + getServletName() + &quot;&#x27;: using default strategies from DispatcherServlet.properties&quot;); &#125; &#125; &#125; DispatcherServlet.properties里的HandlerExceptionResolver配置123org.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver,\\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver 何时加载@ControllerAdvice注解的bean、@ExceptionHandler注解的方法? ExceptionHandlerExceptionResolver实现InitializingBean接口，在afterPropertiesSet方法里调用initExceptionHandlerAdviceCache()方法 在initExceptionHandlerAdviceCache()方法里对@ControllerAdvice注解的bean、@ExceptionHandler注解的方法进行处理 找出所有带有@ControllerAdvice注解的bean，用ExceptionHandlerMethodResolver类判断bean上是否有@ExceptionHandler，有加入exceptionHandlerAdviceCache里 123456789101112131415161718192021222324252627282930313233private void initExceptionHandlerAdviceCache() &#123; if (getApplicationContext() == null) &#123; return; &#125; List&lt;ControllerAdviceBean&gt; adviceBeans = ControllerAdviceBean.findAnnotatedBeans(getApplicationContext()); //找出所有带有@ControllerAdvice注解的bean for (ControllerAdviceBean adviceBean : adviceBeans) &#123; Class&lt;?&gt; beanType = adviceBean.getBeanType(); if (beanType == null) &#123; throw new IllegalStateException(&quot;Unresolvable type for ControllerAdviceBean: &quot; + adviceBean); &#125; ExceptionHandlerMethodResolver resolver = new ExceptionHandlerMethodResolver(beanType); if (resolver.hasExceptionMappings()) &#123; this.exceptionHandlerAdviceCache.put(adviceBean, resolver); &#125; if (ResponseBodyAdvice.class.isAssignableFrom(beanType)) &#123; this.responseBodyAdvice.add(adviceBean); &#125; &#125; if (logger.isDebugEnabled()) &#123; int handlerSize = this.exceptionHandlerAdviceCache.size(); int adviceSize = this.responseBodyAdvice.size(); if (handlerSize == 0 &amp;&amp; adviceSize == 0) &#123; logger.debug(&quot;ControllerAdvice beans: none&quot;); &#125; else &#123; logger.debug(&quot;ControllerAdvice beans: &quot; + handlerSize + &quot; @ExceptionHandler, &quot; + adviceSize + &quot; ResponseBodyAdvice&quot;); &#125; &#125; &#125; 将@ControllerAdvice注解的bean解析方法上ExceptionHandler注解并放入mappedMethods中 1234567891011121314151617181920212223public static final MethodFilter EXCEPTION_HANDLER_METHODS = method -&gt; AnnotatedElementUtils.hasAnnotation(method, ExceptionHandler.class); public ExceptionHandlerMethodResolver(Class&lt;?&gt; handlerType) &#123; for (Method method : MethodIntrospector.selectMethods(handlerType, EXCEPTION_HANDLER_METHODS)) &#123; for (Class&lt;? extends Throwable&gt; exceptionType : detectExceptionMappings(method)) &#123; addExceptionMapping(exceptionType, method); &#125; &#125; &#125;private void addExceptionMapping(Class&lt;? extends Throwable&gt; exceptionType, Method method) &#123; Method oldMethod = this.mappedMethods.put(exceptionType, method); if (oldMethod != null &amp;&amp; !oldMethod.equals(method)) &#123; throw new IllegalStateException(&quot;Ambiguous @ExceptionHandler method mapped for [&quot; + exceptionType + &quot;]: &#123;&quot; + oldMethod + &quot;, &quot; + method + &quot;&#125;&quot;); &#125; &#125;public boolean hasExceptionMappings() &#123; return !this.mappedMethods.isEmpty();&#125; 何时调用到ExceptionHandlerExceptionResolver?– 在DispatcherServlet的doDispatch方法中try-catch的catch代码中调用processDispatchResult方法(),这个方法中调用了processHandlerException方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; ....省略 catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we&#x27;re processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; ...&#125;private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception &#123; boolean errorView = false; if (exception != null) &#123; if (exception instanceof ModelAndViewDefiningException) &#123; logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, exception); mv = ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); &#125; &#125; ....省略&#125;protected ModelAndView processHandlerException(HttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex) throws Exception &#123; // Success and error responses may use different content types request.removeAttribute(HandlerMapping.PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE); // Check registered HandlerExceptionResolvers... ModelAndView exMv = null; //遍历所有的handlerExceptionResolvers，能resolveException返回不空为空跳出循环 if (this.handlerExceptionResolvers != null) &#123; for (HandlerExceptionResolver resolver : this.handlerExceptionResolvers) &#123; exMv = resolver.resolveException(request, response, handler, ex);//此处调用ExceptionHandlerExceptionResolver的resolveException方法 if (exMv != null) &#123; break; &#125; &#125; &#125; ....省略&#125; 调用ExceptionHandlerExceptionResolver的resolveException方法如何处理异常 resolveException方法会调用doResolveHandlerMethodException方法 在doResolveHandlerMethodException方法里 调用getExceptionHandlerMethod方法里 从当前controller类找ExceptionHandler注解的方法，若找到并匹配异常类型返回ServletInvocableHandlerMethod 从exceptionHandlerAdviceCache 里面找到方法并匹配异常类型返回ServletInvocableHandlerMethod 对返回的getExceptionHandlerMethod方法返回值进行判断 不为空 exceptionHandlerMethod.invokeAndHandle(webRequest, mavContainer, arguments); 为空 return null 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118protected ModelAndView doResolveHandlerMethodException(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerMethod handlerMethod, Exception exception) &#123; ServletInvocableHandlerMethod exceptionHandlerMethod = getExceptionHandlerMethod(handlerMethod, exception); if (exceptionHandlerMethod == null) &#123; return null; &#125; ...省略 ServletWebRequest webRequest = new ServletWebRequest(request, response); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); ArrayList&lt;Throwable&gt; exceptions = new ArrayList&lt;&gt;(); try &#123; ...省略 exceptionHandlerMethod.invokeAndHandle(webRequest, mavContainer, arguments); &#125; catch (Throwable invocationEx) &#123; // Any other than the original exception (or a cause) is unintended here, // probably an accident (e.g. failed assertion or the like). if (!exceptions.contains(invocationEx) &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(&quot;Failure in @ExceptionHandler &quot; + exceptionHandlerMethod, invocationEx); &#125; // Continue with default processing of the original exception... return null; &#125; if (mavContainer.isRequestHandled()) &#123; return new ModelAndView(); &#125; else &#123; ModelMap model = mavContainer.getModel(); HttpStatus status = mavContainer.getStatus(); ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model, status); mav.setViewName(mavContainer.getViewName()); if (!mavContainer.isViewReference()) &#123; mav.setView((View) mavContainer.getView()); &#125; if (model instanceof RedirectAttributes) &#123; Map&lt;String, ?&gt; flashAttributes = ((RedirectAttributes) model).getFlashAttributes(); RequestContextUtils.getOutputFlashMap(request).putAll(flashAttributes); &#125; return mav; &#125; &#125; protected ServletInvocableHandlerMethod getExceptionHandlerMethod( @Nullable HandlerMethod handlerMethod, Exception exception) &#123; Class&lt;?&gt; handlerType = null; if (handlerMethod != null) &#123; // Local exception handler methods on the controller class itself. // To be invoked through the proxy, even in case of an interface-based proxy. handlerType = handlerMethod.getBeanType(); ExceptionHandlerMethodResolver resolver = this.exceptionHandlerCache.get(handlerType); if (resolver == null) &#123; resolver = new ExceptionHandlerMethodResolver(handlerType); this.exceptionHandlerCache.put(handlerType, resolver); &#125; Method method = resolver.resolveMethod(exception);//从当前controller类找ExceptionHandler注解的方法 if (method != null) &#123; return new ServletInvocableHandlerMethod(handlerMethod.getBean(), method, this.applicationContext); &#125; // For advice applicability check below (involving base packages, assignable types // and annotation presence), use target class instead of interface-based proxy. if (Proxy.isProxyClass(handlerType)) &#123; handlerType = AopUtils.getTargetClass(handlerMethod.getBean()); &#125; &#125; for (Map.Entry&lt;ControllerAdviceBean, ExceptionHandlerMethodResolver&gt; entry : this.exceptionHandlerAdviceCache.entrySet()) &#123; ControllerAdviceBean advice = entry.getKey(); if (advice.isApplicableToBeanType(handlerType)) &#123; ExceptionHandlerMethodResolver resolver = entry.getValue(); Method method = resolver.resolveMethod(exception);//从exceptionHandlerAdviceCache 里面找到并匹配异常类型 if (method != null) &#123; return new ServletInvocableHandlerMethod(advice.resolveBean(), method, this.applicationContext); &#125; &#125; &#125; return null; &#125; public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) &#123; if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; disableContentCachingIfNecessary(webRequest); mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; &#125; mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;); try &#123; this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(formatErrorForReturnValue(returnValue), ex); &#125; throw ex; &#125; &#125;","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/categories/JAVA/"},{"name":"Spring","slug":"JAVA/Spring","permalink":"https://blog.imder.top/categories/JAVA/Spring/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/tags/Spring/"}]},{"title":"拦截器链式调用","slug":"拦截器链式调用","date":"2022-02-21T16:59:29.000Z","updated":"2024-03-28T16:43:20.083Z","comments":true,"path":"2022/02/21/拦截器链式调用/","link":"","permalink":"https://blog.imder.top/2022/02/21/%E6%8B%A6%E6%88%AA%E5%99%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8/","excerpt":"","text":"拦截器链式调用声明 声明一个接口（校验） 定义校验规则 实现 针对每个规则实现接口 每个规则有校验的先后顺序，继承order接口 抽象类 写一个抽象类：把公共的校验规则写在抽象类 链类 创建一个规则链对象，依赖规则对象","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"}]},{"title":"Springmvc之DispatcherServlet","slug":"springmvc","date":"2022-02-21T14:59:29.000Z","updated":"2024-03-28T16:43:20.075Z","comments":true,"path":"2022/02/21/springmvc/","link":"","permalink":"https://blog.imder.top/2022/02/21/springmvc/","excerpt":"","text":"Springmvc之DispatcherServlet初始化图","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/categories/Spring/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/tags/Spring/"}]},{"title":"Spring循环依赖","slug":"spring循环依赖","date":"2022-02-18T14:59:29.000Z","updated":"2024-03-28T16:43:20.075Z","comments":true,"path":"2022/02/18/spring循环依赖/","link":"","permalink":"https://blog.imder.top/2022/02/18/spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/","excerpt":"","text":"Spring循环依赖循环依赖图 aop创建proxy对象时机 常规一点的就是在BeanFactory.initializeBean()方法里面调用初始化方法之后，调用applyBeanPostProcessorsAfterInitialization() –&gt; AbstractAutoProxyCreator.wrapIfNecessary()生成proxy对象。 还有就是在存在循环依赖的时候，在doCreateBean() –&gt; addSingletonFactory(beanName, () –&gt; getEarlyBeanReference(beanName, mbd, bean)); –&gt; 然后在getSingleton()的时候从三级缓存中取对象的时候，会调用getEarlyBeanReference() –&gt; AbstractAutoProxyCreator.wrapIfNecessary()生成proxy对象。 aop创建案例 第一种情况，Student是代理对象，但是getBean(“teacher”)。 创建Teacher bean 开始populateBean(“student”) 开始创建Student的bean实例 在创建完bean实例的之后也开始populateBean(“teacher”) 开始创建Teacher的bean实例 这时候doGetBean(“teacher”)–&gt;getSingleton(“teacher”)的时候会从三级缓存中获取bean对象，直接返回。 Student继续下面步骤，即initializeBean()–&gt;applyBeanPostProcessorsAfterInitialization()开始为Student创建Proxy对象(因为Teacher是正常的singleton bean) 再返回到Teacher的创建，Teacher设置的就是Student的Proxy对象 然后Teacher继续调用initializeBean()完成初始化。 第二种情况，Student是代理对象，同时getBean(“student”)。 这种情况下就先开始创建Student对象的bean， 同样的开始populateBean(“teacher”)， 开始创建Teacher的bean， 创建完Teacher bean之后，接着开始populateBean(“student”)， 循环依赖开始创建student的bean， 那么这个时候这时候doGetBean(“student”)–&gt;getSingleton(“student”)的时候会从三级缓存中获取bean对象， 跟第一种情况不一样的是，Student是需要被AOP代理的，那么这时候从三级缓存中取出的是getEarlyBeanReference()方法返回的代理对象Proxy， 然后将这个proxy对象放到二级缓存earlySingletonObjects中。 后面Teacher populateBean(“student”)就拿到了Student的代理Proxy，完成Teacher的initializeBean()完成初始化， 然后回到创建student的bean创建，populateBean(“teacher”)设置好Teacher之后， 开始完成student的initializeBean()初始化， 这里applyBeanPostProcessorsAfterInitialization()–&gt;wrapIfNecessary()不会再创建代理对象， 因为缓存earlyProxyReferences里面已经存在student的proxy对象，这也就导致exposedObject = initializeBean(beanName, exposedObject, mbd)这个exposedObject不是代理对象proxy，而是真实对象，如果这样返回就有问题了，所以这里二级缓存的作用就体现出来了，在initializeBean()之后会再次调用getSingleton()去检查二级缓存，此时拿到earlySingletonReference是student对象的proxy对象，那么此时就将exposedObject从真实对象换成proxy代理对象，然后返回。1234567891011if (earlySingletonExposure) &#123; //再次检查二级缓存的值 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; //将真实对象转换成代理Proxy对象 exposedObject = earlySingletonReference; &#125; 。。。省略代码 &#125;&#125; processon地址https://www.processon.com/diagraming/620f41cbe0b34d5aaa947aec","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/categories/Spring/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/tags/Spring/"}]},{"title":"JAVA 对象头情况分析","slug":"java-object-header","date":"2021-12-08T16:14:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/12/08/java-object-header/","link":"","permalink":"https://blog.imder.top/2021/12/08/java-object-header/","excerpt":"","text":"对象头情况分析 32位系统 64位系统 32位系统 锁状态 25bit 4bit 1bit 2bit 23bit 2bit 是否偏向锁 锁标志位 无锁 对象的hashcode 分代年龄 0 01 偏向锁 线程ID Epoch 分代年龄 1 01 轻量级锁 指向栈中的锁记录的指针 00 重量级锁 指向重量级锁的指针 10 GC标记 空 11 64位系统 锁状态 61bit 是否偏向锁 1bit 锁标志 2bit 无锁 unused 25bit 对象的hashcode 31bit unused 1bit 分代年龄 4bit 0 01 偏向锁 线程ID 54bit Epoch 2bit unused 1bit 分代年龄 4bit 1 01 轻量级锁 指向栈中的锁记录的指针 00 重量级锁 指向重量级锁的指针 10 GC标记 空 11 jvm是如何使用锁和markword? 当对象没有被加锁，一个普通的对象，MarkWord记录对象的hashcode，锁标志位01，是否偏向锁0 当对象被当做同步锁并有一个线程A抢到锁时，锁标志位 01 偏向锁改成1，前23bit记录抢到锁的线程id,表示进入偏向状态 当线程A再次试图来获得锁时，JVM发现同步锁对象的标志位是01，是否偏向锁是1，也就是偏向状态，Mark Word中记录的线程id就是线程A自己的id，表示线程A已经获得了这个偏向锁，可以执行同步锁的代码 当线程B试图获得这个锁时，JVM发现同步锁处于偏向状态，但是Mark Word中的线程id记录的不是B，那么线程B会先用CAS操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程A一般不会自动释放偏向锁。如果抢锁成功，就把Mark Word里的线程id改为线程B的id，代表线程B获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行步骤5。 偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。JVM会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，同时在对象锁Mark Word中保存指向这片空间的指针。上述两个保存操作都是CAS操作，如果保存成功，代表线程抢到了同步锁，就把Mark Word中的锁标志位改成00，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行步骤6。 轻量级锁抢锁失败，JVM会使用自旋锁，自旋锁不是一个锁状态，只是代表不断的重试，尝试抢锁。从JDK1.7开始，自旋锁默认启用，自旋次数由JVM决定。如果抢锁成功则执行同步锁代码，如果失败则继续执行步骤7。 自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为10。在这个状态下，未抢到锁的线程都会被阻塞。","categories":[{"name":"java对象","slug":"java对象","permalink":"https://blog.imder.top/categories/java%E5%AF%B9%E8%B1%A1/"}],"tags":[{"name":"内存","slug":"内存","permalink":"https://blog.imder.top/tags/%E5%86%85%E5%AD%98/"},{"name":"java","slug":"java","permalink":"https://blog.imder.top/tags/java/"}]},{"title":"LJ16购物单","slug":"huawei_lj16","date":"2021-11-30T11:43:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj16/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj16/","excerpt":"","text":"购物单描述王强今天很开心，公司发给N元的年终奖。王强决定把年终奖用于购物，他把想买的物品分为两类：主件与附件，附件是从属于某个主件的，下表就是一些主件与附件的例子： 主件 附件 电脑 打印机，扫描仪 书柜 图书 书桌 台灯文具 工作椅 无 如果要买归类为附件的物品，必须先买该附件所属的主件。每个主件可以有 0 个、 1 个或 2 个附件。附件不再有从属于自己的附件。王强想买的东西很多，为了不超出预算，他把每件物品规定了一个重要度，分为 5 等：用整数 1 ~ 5 表示，第 5 等最重要。他还从因特网上查到了每件物品的价格（都是 10 元的整数倍）。他希望在不超过 N 元（可以等于 N 元）的前提下，使每件物品的价格与重要度的乘积的总和最大。 设第 j 件物品的价格为 v[j] ，重要度为 w[j] ，共选中了 k 件物品，编号依次为 j 1 ， j 2 ，……， j k ，则所求的总和为：v[j 1 ]*w[j 1 ]+v[j 2 ]*w[j 2 ]+ … +v[j k ]*w[j k ] 。（其中 * 为乘号） 请你帮助王强设计一个满足要求的购物单。 输入描述：输入的第 1 行，为两个正整数，用一个空格隔开：N m（其中 N （ &lt;32000 ）表示总钱数， m （ &lt;60 ）为希望购买物品的个数。） 从第 2 行到第 m+1 行，第 j 行给出了编号为 j-1 的物品的基本数据，每行有 3 个非负整数 v p q （其中 v 表示该物品的价格（ v&lt;10000 ）， p 表示该物品的重要度（ 1 ~ 5 ）， q 表示该物品是主件还是附件。如果 q=0 ，表示该物品为主件，如果 q&gt;0 ，表示该物品为附件， q 是所属主件的编号） 输出描述： 输出文件只有一个正整数，为不超过总钱数的物品的价格与重要度乘积的总和的最大值（ &lt;200000 ）。","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ15求int型正整数在内存中存储时1的个数","slug":"huawei_lj15","date":"2021-11-30T11:42:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj15/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj15/","excerpt":"","text":"求int型正整数在内存中存储时1的个数描述输入一个 int 型的正整数，计算出该 int 型数据在内存中存储时 1 的个数。 数据范围：保证在 32 位整型数字范围内 输入描述： 输入一个整数（int类型） 输出描述： 这个数转换成2进制后，输出1的个数 代码实现123456789101112131415 import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); scanner.nextLine(); String s = Integer.toString(n, 2); int length = s.replaceAll(&quot;[^1]&quot;, &quot;&quot;).length(); System.out.println(length); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ14字符串排序","slug":"huawei_lj14","date":"2021-11-30T11:41:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj14/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj14/","excerpt":"","text":"字符串排序描述给定 n 个字符串，请对 n 个字符串按照字典序排列。 输入描述：输入第一行为一个正整数n(1≤n≤1000),下面n行为n个字符串(字符串长度≤100),字符串中只含有大小写字母。 输出描述：数据输出n行，输出结果为按照字典序排列的字符串。 代码实现1234567891011121314151617181920212223242526import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); scanner.nextLine(); List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) &#123; String s = scanner.nextLine(); list.add(s); &#125; list.sort(new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o1.compareTo(o2); &#125; &#125;); for (String c : list) &#123; System.out.println(c); &#125; &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ13句子逆序","slug":"huawei_lj13","date":"2021-11-30T11:40:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj13/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj13/","excerpt":"","text":"句子逆序描述将一个英文语句以单词为单位逆序排放。例如“I am a boy”，逆序排放后为“boy a am I”所有单词之间用一个空格隔开，语句中除了英文字母外，不再包含其他字符 数据范围：输入的字符串长度满足 注意本题有多组输入 输入描述：输入一个英文语句，每个单词用空格隔开。保证输入只包含空格和字母。 输出描述：得到逆序的句子 代码实现12345678910111213141516171819202122232425import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String num = scanner.nextLine(); String[] s = num.split(&quot; &quot;); List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (String c : s) &#123; list.add(c); &#125; Collections.reverse(list); String result = &quot;&quot;; for (int i = 0; i &lt; list.size(); i++) &#123; result += list.get(i); if (i + 1 != list.size()) &#123; result += &quot; &quot;; &#125; &#125; System.out.println(result); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ12字符串反转","slug":"huawei_lj12","date":"2021-11-30T11:30:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj12/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj12/","excerpt":"","text":"字符串反转描述接受一个只包含小写字母的字符串，然后输出该字符串反转后的字符串。（字符串长度不超过1000） 输入描述：输入一行，为一个只包含小写字母的字符串。 输出描述：输出该字符串反转后的字符串。 代码实现12345678910111213import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String num = scanner.nextLine(); System.out.println(new StringBuilder(num).reverse().toString()); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ11数字颠倒","slug":"huawei_lj11","date":"2021-11-30T11:20:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj11/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj11/","excerpt":"","text":"数字颠倒描述输入一个整数，将这个整数以字符串的形式逆序输出程序不考虑负数的情况，若数字含有0，则逆序形式也含有0，如输入为100，则输出为001 输入描述：输入一个int整数 输出描述：将这个整数以字符串的形式逆序输出 代码实现12345678910111213import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String num = scanner.nextLine(); System.out.println(new StringBuilder(num).reverse().toString()); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ10字符个数统计","slug":"huawei_lj10","date":"2021-11-30T11:10:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/30/huawei_lj10/","link":"","permalink":"https://blog.imder.top/2021/11/30/huawei_lj10/","excerpt":"","text":"字符个数统计描述编写一个函数，计算字符串中含有的不同字符的个数。字符在 ASCII 码范围内( 0~127 ，包括 0 和 127 )，换行表示结束符，不算在字符里。不在范围内的不作统计。多个相同的字符只计算一次例如，对于字符串 abaca 而言，有 a、b、c 三种不同的字符，因此输出 3 。 数据范围： 输入描述：输入一行没有空格的字符串。 输出描述：输出 输入字符串 中范围在(0~127，包括0和127)字符的种数。 代码实现1234567891011121314151617import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String num = scanner.nextLine(); Set&lt;Character&gt; sets = new HashSet&lt;&gt;(); for (char c : num.toCharArray()) &#123; sets.add(c); &#125; System.out.println(sets.size()); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ9提取不重复的数","slug":"huawei_lj9","date":"2021-11-29T20:10:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/29/huawei_lj9/","link":"","permalink":"https://blog.imder.top/2021/11/29/huawei_lj9/","excerpt":"","text":"提取不重复的数描述输入一个 int 型整数，按照从右向左的阅读顺序，返回一个不含重复数字的新的整数。保证输入的整数最后一位不是 0 。 数据范围： 输入描述：输入一个int型整数 输出描述：按照从右向左的阅读顺序，返回一个不含重复数字的新的整数 代码实现12345678910111213141516171819202122import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String num = scanner.nextLine(); String reversenum = new StringBuilder(num).reverse().toString(); char[] chars = reversenum.toCharArray(); String print = &quot;&quot;; ArrayList&lt;Character&gt; characters = new ArrayList&lt;&gt;(); for (char c : chars) &#123; if (!characters.contains(c)) &#123; characters.add(c); print += c; &#125; &#125; System.out.println(print); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ8合并表记录","slug":"huawei_lj8","date":"2021-11-29T16:35:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/29/huawei_lj8/","link":"","permalink":"https://blog.imder.top/2021/11/29/huawei_lj8/","excerpt":"","text":"合并表记录描述数据表记录包含表索引和数值（int范围的正整数），请对表索引相同的记录进行合并，即将相同索引的数值进行求和运算，输出按照key值升序进行输出。 提示:0 &lt;= index &lt;= 111111111 &lt;= value &lt;= 100000 输入描述：先输入键值对的个数n（1 &lt;= n &lt;= 500）然后输入成对的index和value值，以空格隔开 输出描述：输出合并后的键值对（多行） 代码实现12345678910111213141516171819202122232425262728293031323334353637import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int num = scanner.nextInt(); scanner.nextLine(); List&lt;Integer &gt; keys = new ArrayList&lt;&gt;(); Map&lt;Integer,Integer&gt; datamap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; num; i++) &#123; String s = scanner.nextLine(); String[] s1 = s.split(&quot; &quot;); Integer key = Integer.parseInt(s1[0]); int value =Integer.parseInt(s1[1]); if (datamap.get(key)!=null)&#123; datamap.put(key,datamap.get(key) + value); &#125;else&#123; datamap.put(key,value); keys.add(key); &#125; &#125; keys.sort(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;); for (Integer key : keys) &#123; System.out.println(key + &quot; &quot; +datamap.get(key)); &#125; &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ7取近似值","slug":"huawei_lj7","date":"2021-11-29T16:33:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/29/huawei_lj7/","link":"","permalink":"https://blog.imder.top/2021/11/29/huawei_lj7/","excerpt":"","text":"取近似值描述写出一个程序，接受一个正浮点数值，输出该数值的近似整数值。如果小数点后数值大于等于 0.5 ,向上取整；小于 0.5 ，则向下取整。 数据范围：保证输入的数字在 32 位浮点数范围内 输入描述：输入一个正浮点数值 输出描述：输出该数值的近似整数值 代码实现123456789101112131415import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); double input = scanner.nextDouble(); System.out.println(Math.round(input)); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ6质数因子","slug":"huawei_lj6","date":"2021-11-28T21:33:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/28/huawei_lj6/","link":"","permalink":"https://blog.imder.top/2021/11/28/huawei_lj6/","excerpt":"","text":"质数因子描述功能:输入一个正整数，按照从小到大的顺序输出它的所有质因子（重复的也要列举）（如180的质因子为2 2 3 3 5 ） 输入描述：输入一个整数 输出描述：按照从小到大的顺序输出它的所有质数的因子，以空格隔开。最后一个数后面也要有空格。 代码实现12345678910111213141516171819202122232425import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int input = scanner.nextInt(); for (int i = 2; i &lt;= Math.sqrt(input); i++) &#123; while (input % i == 0)&#123; System.out.print(i + &quot; &quot;); input = input / i; &#125; &#125; if (input &gt; 1 )&#123; System.out.print(input + &quot; &quot;); &#125; &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ5进制转换","slug":"huawei_lj5","date":"2021-11-28T20:33:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/28/huawei_lj5/","link":"","permalink":"https://blog.imder.top/2021/11/28/huawei_lj5/","excerpt":"","text":"进制转换描述写出一个程序，接受一个十六进制的数，输出该数值的十进制表示。 数据范围：保证结果在 注意本题有多组输入 输入描述：输入一个十六进制的数值字符串。注意：一个用例会同时有多组输入数据，请参考帖子https://www.nowcoder.com/discuss/276处理多组输入的问题。 输出描述：输出该数值的十进制字符串。不同组的测试用例用\\n隔开。 代码实现1234567891011121314151617181920212223import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); List&lt;Integer&gt; strInput = new ArrayList&lt;&gt;(); while (scanner.hasNext()) &#123; String inputStr = scanner.nextLine(); int i = Integer.parseInt(inputStr.substring(2), 16); strInput.add(i); &#125; for (Integer i : strInput) &#123; System.out.println(i); &#125; &#125;&#125; java进制通用转换r进制转10进制Integer.parseInt(str,r); 10进制转r进制Integer.toString(int,r);","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ4字符串分割","slug":"huawei_lj4","date":"2021-11-28T10:33:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/28/huawei_lj4/","link":"","permalink":"https://blog.imder.top/2021/11/28/huawei_lj4/","excerpt":"","text":"字符串分割描述•连续输入字符串，请按长度为8拆分每个输入字符串并进行输出；•长度不是8整数倍的字符串请在后面补数字0，空字符串不处理。 输入描述：连续输入字符串(输入多次,每个字符串长度小于等于100) 输出描述：依次输出所有分割后的长度为8的新字符串 代码实现123456789101112131415161718192021222324252627282930313233343536import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); List&lt;String&gt; strInput = new ArrayList&lt;&gt;(); while (scanner.hasNext()) &#123; String s = scanner.nextLine(); strInput.addAll(strInput(s)); &#125; for (String str : strInput) &#123; System.out.println(str); &#125; &#125; public static List&lt;String&gt; strInput(String input) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); while (input.length() &gt;= 8) &#123; result.add(input.substring(0, 8)); input = input.substring(8); &#125; int len = input.length(); if (len != 0) &#123; input += &quot;00000000&quot;.substring(0, 8 - len); result.add(input); &#125; return result; &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ3明明的随机数","slug":"huawei_lj3","date":"2021-11-28T10:06:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/28/huawei_lj3/","link":"","permalink":"https://blog.imder.top/2021/11/28/huawei_lj3/","excerpt":"","text":"明明的随机数描述明明想在学校中请一些同学一起做一项问卷调查，为了实验的客观性，他先用计算机生成了 N 个 1 到 1000 之间的随机整数（ N≤1000 ），对于其中重复的数字，只保留一个，把其余相同的数去掉，不同的数对应着不同的学生的学号。然后再把这些数从小到大排序，按照排好的顺序去找同学做调查。请你协助明明完成“去重”与“排序”的工作(同一个测试用例里可能会有多组数据(用于不同的调查)，希望大家能正确处理)。 注：测试用例保证输入参数的正确性，答题者无需验证。测试用例不止一组。当没有新的输入时，说明输入结束。 数据范围：输入的数字大小满足 0 &lt; n &lt; 1000 ,输入数字的大小满足 1 &lt;= val &lt;= 500 输入描述：注意：输入可能有多组数据(用于不同的调查)。每组数据都包括多行，第一行先输入随机整数的个数 N ，接下来的 N 行再输入相应个数的整数。具体格式请看下面的”示例”。 输出描述：返回多行，处理后的结果 代码实现1234567891011121314151617181920212223242526272829303132333435import java.util.*;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); List&lt;List&lt;Integer&gt;&gt; mlist = new ArrayList(); while (scanner.hasNext()) &#123; int size = scanner.nextInt(); HashSet&lt;Integer&gt; dataset = new HashSet&lt;&gt;(); List&lt;Integer&gt; data = null; for (int i = 0; i &lt; size; i++) &#123; dataset.add(scanner.nextInt()); &#125; data = new ArrayList&lt;&gt;(dataset); data.sort(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;); mlist.add(data); &#125; for (List&lt;Integer&gt; printData : mlist) &#123; for (Integer i : printData) System.out.println(i); &#125; &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ2计算某字符出现次数","slug":"huawei_lj2","date":"2021-11-28T09:14:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/28/huawei_lj2/","link":"","permalink":"https://blog.imder.top/2021/11/28/huawei_lj2/","excerpt":"","text":"计算某字符出现次数描述写出一个程序，接受一个由字母、数字和空格组成的字符串，和一个字符，然后输出输入字符串中该字符的出现次数。（不区分大小写字母） 数据范围： 输入的数据有可能包含大小写字母、数字和空格 输入描述：第一行输入一个由字母和数字以及空格组成的字符串，第二行输入一个字符。 输出描述：输出输入字符串中含有该字符的个数。（不区分大小写字母） 代码实现123456789101112131415import java.util.Scanner;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String allstr = scanner.nextLine().toUpperCase(); String single= scanner.nextLine().toUpperCase(); System.out.println(allstr.replaceAll(&quot;[^&quot;+single + &quot;]&quot;,&quot;&quot;).length()); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"LJ1计算字符串最后一个单词的长度","slug":"huawei_lj1","date":"2021-11-28T09:10:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/28/huawei_lj1/","link":"","permalink":"https://blog.imder.top/2021/11/28/huawei_lj1/","excerpt":"","text":"计算字符串最后一个单词的长度描述计算字符串最后一个单词的长度，单词以空格隔开，字符串长度小于5000。（注：字符串末尾不以空格为结尾） 输入描述：输入一行，代表要计算的字符串，非空，长度小于5000。 输出描述：输出一个整数，表示输入字符串最后一个单词的长度。 代码实现123456789101112131415import java.util.Scanner;/** * author renzhengxiao */public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String allwords = scanner.nextLine(); int index = allwords.lastIndexOf(&quot; &quot;); String word= allwords.substring(index+1,allwords.length()); System.out.println(word.length()); &#125;&#125;","categories":[{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"JAVA虚拟机","slug":"jvm-virtual","date":"2021-11-25T19:20:47.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/25/jvm-virtual/","link":"","permalink":"https://blog.imder.top/2021/11/25/jvm-virtual/","excerpt":"","text":"JVM虚拟机 栈 每开启一个线程，就开辟一块栈内存区域 栈帧：遇到一方法就新建一块栈帧放入栈中 方法执行完，对应栈帧出栈销毁 栈帧 局部变量表 ：存局部变量 操作数栈 ： 做运算 动态链接 ：方法入口地址 符号引用转为入口地址 方法出口 反汇编查看字节码文件javap -c ***.class 单个栈空间大小设置参数-Xss128k （默认1m） 栈空间满了会出现StackOverFlowError，调用链过长可能导致此位置，或者递归调用 堆 堆参数设置： -Xms 初始堆大小 例：-Xms256m -Xmx 最大堆大小 例：-Xms256m -Xmn 新生代大小 例：-Xmn1m 方法区(元空间)主要存常量，静态变量，类元信息 jdk1.8类元数据放到了本地内存中，将常量池和静态变量放到了Java堆， jdk1.7 及以前存储堆中在持久代 方法区设置参数1.8 -XX:MetaspaceSize: -XX:MetaspaceSize: 程序计数器存储正在执行的语句的行号（地址），线程私有，当语句执行完成，字节码执行引擎对程序计数器进行修改 GCgc类型 full gc 回收年轻代、老年代、方法区无引用对象 minor gc 回收eden survivor区无引用对象 注意：gc回收过程中都会 stop the world (STW) 如果回收后仍没有空间放对象，OutOfMemoryError minor gc 回收 eden区 from区 将存活对象移入to区 minor gc 回收eden区 to 区，将存活对象移入from区 逃逸分析jvm运行模式（java命令运行java类） 解释模式：执行一行jvm字节码编译一行机器码执行 ，启动快执行慢 编译模式：一次性编译成机器码一次性执行 启动慢 执行快 混合模式：使用解释模式，热点代码使用编译模式 逃逸分析参数开启：-XX:+DoEscapeAnalysis 关闭：-XX:-DoEscapeAnalysis jdk1.8默认开启 逃逸分析说明如果一个方法中的对象在方法结束时，这个对象就可以被回收，jvm会将这个对象分配栈帧里，如果栈空间不够，分配在堆里，栈帧弹出就回收，不需要等待内存满触发GC 垃圾回收 对象优先分配eden区 大对象可以直接进入老年代，避免在年轻代来回复制，大对象复制比较耗时 minor gc后survivor区放不下的对象直接进入老年代 动态年龄判断 ：年龄1+…年龄n &gt; survivor区大小50% 那么年龄大于n的对象直接进入老年代 老年代空间担保机制 -XX:-HandlePromotionFailure 1.8默认设置 如何判断对象可以被回收？ 引用计数器：计数为0 可以回收，存在问题就是循环依赖，A对象一属性依赖B B对象一属性依赖A 可达性分析算法：GCRoot根，遍历GCroot根 线程栈局部变量 静态变量 本地方法栈变量 如何判断一个类时无用类？ 类的所有实例被回收 加载该类的classloader被回收 该类对应的java.lang.class对象任何地方没有被引用，Class..forName() 当对象第一次被标记为垃圾对象，如何拯救对象变为正常对象？重写finalize方法，重新建立引用关系，第二次标记回调用该对象的finalize方法 垃圾回收算法 标记清除：标记需回收的对象，然后一个一个清理 效率较低 空间利用率低，清除后产生不连续碎片 复制算法：内存分为两块，分配对象使用其中一块，垃圾回收时，将存活对象复制到另一块，剩余一次性清理掉 效率快 空间利用率低 一般来说年轻代使用复制算法 标记整理算法：标记出垃圾对象，将存活对象向一端移动，然后清理端边界以外的内存 分代收集算法：年轻代和老年代使用不同垃圾收集算法 垃圾收集器Serial收集器 使用参数 算法 年轻代 -XX:+UseSerialGC 复制算法 老年代 -XX:+UseSerialOldGC 标记整理算法 说明：单线程收集，收集时必须暂停应用程序线程 stw 优点： 简单高效 缺点： 对多核cpu来说 效率不高 ParNew收集器说明：是Serial收集器的多线程版本 XX:+UseParNewGC，打开该开关后，使用ParNew(年轻代)+Serial Old(老年代)组合进行GC。另外，ParNew是CMS收集器的默认年轻代收集器。 老年代使用标记整理算法，年轻代是复制算法 ParNew用于垃圾回收的线程可用参数**-XX:ParallelGCThreads=n**进行配置,建议n与主机逻辑cpu数一致。 ParallelScavenge收集器是内存大于2G，2个cpu下的默认收集器 说明：关注吞吐量，关注用户线程的停顿时间 所谓吞吐量，就是cpu用于执行用户代码时间与cpu消耗时间的比值 使用参数 算法 年轻代 -XX:+UseParallelGC 复制算法 老年代 -XX:+UseParallelOldGC 标记整理算法 CMS收集器相关参数： -XX:+UseConcMarkSweepGC 启动cms -XX:ConcGCThreads 并发GC的线程数 -XX:+UseCMSCompactAtFullCollection fullgc之后做压缩整理 -XX:+CMSFullGCsBeforeCompaction 几次fullgc做一次压缩，默认是0 -XX:CMSInitiatingOccupancyFraction 老年代使用达到该比例出发fullgc 默认是92，百分比 -XX:+UseCMSInitiatingOccupancyOnly 只使用设定的回收阈值(- XX:CMSInitiatingOccupancyFraction设定的值) 如果没有指定这个值，只有第一次使用指定值，后续自动调整 -XX:+CMSScavengeBeforeRemark 在fullgc之前先minor gc一次，目的在于减少老年代对年轻代的引用，降低cms gc 标记阶段开销，一般cms的gc耗时80%都在remark阶段 cms收集器步骤： 初始标记：STW 记录gcRoot根直接引用的对象 速度很快 并发标记：NO STW 全链路标记gcRoot ，耗时长 重新标记：STW 修正并发标记应用程序运行导致标记产生变动的对象，比初始标记稍微耗时长一点 并发清理：NO STW 清理 cms收集器的缺陷： 产生浮动垃圾，并发清理又产生垃圾 cpu资源抢占 使用标记清除算法，产生碎片 在执行gc过程中，一边标记/回收，一边产生新的垃圾，可能导致再一次的fullgc ,此时会进入stw,使用serial收集器收集","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/categories/JAVA/"}],"tags":[{"name":"JAVA虚拟机","slug":"JAVA虚拟机","permalink":"https://blog.imder.top/tags/JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"}]},{"title":"JVM类加载子系统","slug":"jvm_class_child_system","date":"2021-11-25T14:59:29.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/25/jvm_class_child_system/","link":"","permalink":"https://blog.imder.top/2021/11/25/jvm_class_child_system/","excerpt":"","text":"类加载流程 加载：从硬盘读取class文件 验证：验证字节码准确性 准备：类静态变量赋值，默认值基础类型0，false等等，对象类型null 解析：将符号引用替换为直接引用 静态链接：main方法替换为指向数据所存内存区域的指针 动态链接：运行期间将符号引用替换为指向内存区域的指针 初始化：类的静态变量初始化为制定的值，执行静态代码块 类加载器与双亲委派机制 启动类加载器：加载jre/lib下的核心类库 扩展类加载器：加载lib/ext 下的jar包 应用程序加载器：加载自己写的类 自定义类加载器：加载自定义路径的类 打印 启动类加载器 打印出null？原因：c语言实现，java里找不到打印null 自定义类加载器 重写loadClass方法 重写findClass方法 ClassLoader 抽象类 未实现findClass方法 ​ loadClass方法 先从父加载器加载 若父加载器加载不到 ,用bootstrap加载器加载（c语言实现，java调用native方法） 若经过上述两步还加载不到则调用自己findClass方法 defineClass方法：将二进制字节码文件加载成class对象 双亲委派机制 为什么使用双亲委派机制？ 沙箱安全机制，例如自己写java.lang.String 不会被应用程序加载器（自定义类加载器）加载，防止核心类被篡改 避免类的重复加载 如何打印程序加载类信息？ -verbose:class A a = null，请问是否加载字节码？不加载字节码 打破双亲委派？tomcat类加载打破 一个容器部署多个应用程序，不同的程序依赖同一类库的版本不同 同类库相同可以共存 tomcat容器有自己的依赖类库，不能与应用程序类库混淆 支持jsp的修改 注意： 每个war包都有一个webAppClassLoader加载 早期tomcat有common、server、 shared目录 分别对应CommonClassLoader,CatalinaClassLoader,SharedClassLoader 类加载器如何为parent赋值？程序启动时调用jvm.dll加载启动类加载器，由启动类加载其他类加载器并对parent进行赋值","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://blog.imder.top/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"JAVA 对象占内存情况分析","slug":"java_memory","date":"2021-11-24T16:14:00.000Z","updated":"2024-03-28T16:43:20.063Z","comments":true,"path":"2021/11/24/java_memory/","link":"","permalink":"https://blog.imder.top/2021/11/24/java_memory/","excerpt":"","text":"对象组成结构 对象头 对象实例数据 对象头 对象头 32bit系统 64bit系统 _mark 4byte 8byte _klass 4byte 8byte(64位指针压缩4byte) _length 4byte 4byte 64位系统在内存小于32G情况下默认开启指针压缩；在开启指针压缩时，64位系统 _klass 占用4byte 注意： 对象头中_length 只有数组才有此字段 klass类指针，指向类元数据的指针 对象实例数据 数据类型 占用空间大小 32位系统 占用空间大小 64位系统 long/double 8byte 8byte int/float 4byte 4byte short/char 2byte 2byte boolean/byte 1byte 1byte reference 4byte 8byte(64位指针压缩4byte) 对象实例数据对齐，对象首地址必须为该对象占用空间的整数倍 例如 int类型实例的首地址 %4 =0 如果不满足，则需要对齐填空padding 使其满足 对象实例数据在内存排序规则： long/double，int/float,short/char,boolean/byte,reference 对象对齐：(对象尾 + padding) % 8 = 0 ; 0 &lt; padding &lt; 8 查看普通java对象的内部布局工具12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 对象大小测试 java代码 123456import org.openjdk.jol.info.ClassLayout;public class Main &#123; public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(new Object()).toPrintable()); &#125;&#125; 开启指针压缩 -XX:+UseCompressedOops 12345678java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 28 0f 00 00 (00101000 00001111 00000000 00000000) (3880) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 由此可见 上述第三个 object header 为kclass指针，占用空间4bytes 关闭指针压缩-XX:-UseCompressedOops 12345678java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 00 1c 1c 12 (00000000 00011100 00011100 00010010) (303832064) 12 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1)Instance size: 16 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total 由此可见，上述第三个第四个objectheader 为Klass指针，占用空间8bytes 数组对象测试 java代码 123456import org.openjdk.jol.info.ClassLayout;public class Main &#123; public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(new Object[10]).toPrintable()); &#125;&#125; 指针压缩情况下输出 123456789[Ljava.lang.Object; object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 60 1a 01 00 (01100000 00011010 00000001 00000000) (72288) 12 4 (object header) 0a 00 00 00 (00001010 00000000 00000000 00000000) (10) 16 40 java.lang.Object Object;.&lt;elements&gt; N/AInstance size: 56 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total 由此可见 第四个header为数组长度，同时reference类型占用4bytes 关闭指针压缩情况下输出 1234567891011[Ljava.lang.Object; object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) d8 9c 3a 16 (11011000 10011100 00111010 00010110) (372939992) 12 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 16 4 (object header) 0a 00 00 00 (00001010 00000000 00000000 00000000) (10) 20 4 (alignment/padding gap) 24 80 java.lang.Object Object;.&lt;elements&gt; N/AInstance size: 104 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total 由此可见，第五个为header为数组长度，同时reference类型占用8bytes","categories":[{"name":"java对象","slug":"java对象","permalink":"https://blog.imder.top/categories/java%E5%AF%B9%E8%B1%A1/"}],"tags":[{"name":"内存","slug":"内存","permalink":"https://blog.imder.top/tags/%E5%86%85%E5%AD%98/"},{"name":"java","slug":"java","permalink":"https://blog.imder.top/tags/java/"}]}],"categories":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.imder.top/categories/zookeeper/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.imder.top/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"springboot","slug":"springboot","permalink":"https://blog.imder.top/categories/springboot/"},{"name":"微服务","slug":"微服务","permalink":"https://blog.imder.top/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/categories/Spring/"},{"name":"redis","slug":"redis","permalink":"https://blog.imder.top/categories/redis/"},{"name":"JAVA虚拟机","slug":"JAVA虚拟机","permalink":"https://blog.imder.top/categories/JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"消息队列","slug":"消息队列","permalink":"https://blog.imder.top/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Mysql","slug":"Mysql","permalink":"https://blog.imder.top/categories/Mysql/"},{"name":"逻辑","slug":"逻辑","permalink":"https://blog.imder.top/categories/%E9%80%BB%E8%BE%91/"},{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/categories/Springcloud/"},{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/categories/JAVA/"},{"name":"Spring","slug":"JAVA/Spring","permalink":"https://blog.imder.top/categories/JAVA/Spring/"},{"name":"java对象","slug":"java对象","permalink":"https://blog.imder.top/categories/java%E5%AF%B9%E8%B1%A1/"},{"name":"华为面试题","slug":"华为面试题","permalink":"https://blog.imder.top/categories/%E5%8D%8E%E4%B8%BA%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.imder.top/tags/zookeeper/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.imder.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"tomcat","slug":"tomcat","permalink":"https://blog.imder.top/tags/tomcat/"},{"name":"springboot","slug":"springboot","permalink":"https://blog.imder.top/tags/springboot/"},{"name":"微服务","slug":"微服务","permalink":"https://blog.imder.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"远程服务调用","slug":"远程服务调用","permalink":"https://blog.imder.top/tags/%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8/"},{"name":"JAVA","slug":"JAVA","permalink":"https://blog.imder.top/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.imder.top/tags/Spring/"},{"name":"redis","slug":"redis","permalink":"https://blog.imder.top/tags/redis/"},{"name":"JAVA虚拟机","slug":"JAVA虚拟机","permalink":"https://blog.imder.top/tags/JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"消息队列","slug":"消息队列","permalink":"https://blog.imder.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Mysql","slug":"Mysql","permalink":"https://blog.imder.top/tags/Mysql/"},{"name":"逻辑","slug":"逻辑","permalink":"https://blog.imder.top/tags/%E9%80%BB%E8%BE%91/"},{"name":"Springcloud","slug":"Springcloud","permalink":"https://blog.imder.top/tags/Springcloud/"},{"name":"内存","slug":"内存","permalink":"https://blog.imder.top/tags/%E5%86%85%E5%AD%98/"},{"name":"java","slug":"java","permalink":"https://blog.imder.top/tags/java/"},{"name":"面试题","slug":"面试题","permalink":"https://blog.imder.top/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://blog.imder.top/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]}